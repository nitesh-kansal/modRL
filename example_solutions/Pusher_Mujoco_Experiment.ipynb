{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe929c1-4eb0-451e-9f43-3e23317581b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "250708ab-d74e-4b44-a6cb-4d8a3a61f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import beta\n",
    "import numpy as np\n",
    "class Policy_Network(nn.Module):\n",
    "    def __init__(self, input_size, action_size):\n",
    "        super(Policy_Network, self).__init__()\n",
    "        # outputs beta likelyhood parameters\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 2*action_size)\n",
    "        self.fcalpha = nn.Linear(2*action_size, action_size)\n",
    "        self.fcbeta = nn.Linear(2*action_size, action_size)\n",
    "        self.softplus_act = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        a = self.softplus_act(self.fcalpha(x)) + 1.\n",
    "        b = self.softplus_act(self.fcbeta(x)) + 1.\n",
    "        beta_dist = beta.Beta(a,b)\n",
    "        return beta_dist, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbbfa0ee-4cc7-4fee-b651-40448b59569a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import beta\n",
    "import numpy as np\n",
    "class Policy_Value_Network(nn.Module):\n",
    "    def __init__(self, input_size, action_size):\n",
    "        super(Policy_Value_Network, self).__init__()\n",
    "        # outputs beta likelyhood parameters\n",
    "        self.policy_network = Policy_Network(input_size, action_size)\n",
    "        self.fcval = nn.Linear(2*action_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        beta_dist,x = self.policy_network(x)\n",
    "        values = self.fcval(x)\n",
    "        return beta_dist, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b2e519-23e3-4d65-9d58-4280209234f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/Users/n0k03zp/rl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f99ef8-bc18-41c8-b634-265e96b4159e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space: Box(-2.0, 2.0, (20, 7), float32)\n",
      "raw state space : Box(-inf, inf, (20, 23), float64)\n",
      "inside a2c\n",
      " Episode : 100\t Average reward in last 100 episode : -791.20 epsilon_policy : 0.199 epsilon_value : 4.975 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 200\t Average reward in last 100 episode : -576.15 epsilon_policy : 0.198 epsilon_value : 4.950 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 300\t Average reward in last 100 episode : -523.79 epsilon_policy : 0.197 epsilon_value : 4.926 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 400\t Average reward in last 100 episode : -509.53 epsilon_policy : 0.196 epsilon_value : 4.901 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 500\t Average reward in last 100 episode : -497.94 epsilon_policy : 0.195 epsilon_value : 4.877 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 600\t Average reward in last 100 episode : -488.84 epsilon_policy : 0.194 epsilon_value : 4.852 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 700\t Average reward in last 100 episode : -467.76 epsilon_policy : 0.193 epsilon_value : 4.828 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 800\t Average reward in last 100 episode : -450.81 epsilon_policy : 0.192 epsilon_value : 4.804 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 900\t Average reward in last 100 episode : -446.36 epsilon_policy : 0.191 epsilon_value : 4.780 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 1000\t Average reward in last 100 episode : -440.46 epsilon_policy : 0.190 epsilon_value : 4.756 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " score @ 992 = -0.57914871500676586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py:912: GLFWError: (65537) b'The GLFW library is not initialized'\n",
      "  warnings.warn(message, GLFWError)\n",
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 1100\t Average reward in last 100 episode : -436.81 epsilon_policy : 0.189 epsilon_value : 4.732 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1200\t Average reward in last 100 episode : -426.54 epsilon_policy : 0.188 epsilon_value : 4.709 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1300\t Average reward in last 100 episode : -420.57 epsilon_policy : 0.187 epsilon_value : 4.685 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1400\t Average reward in last 100 episode : -418.58 epsilon_policy : 0.186 epsilon_value : 4.662 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1500\t Average reward in last 100 episode : -416.88 epsilon_policy : 0.186 epsilon_value : 4.639 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1600\t Average reward in last 100 episode : -412.67 epsilon_policy : 0.185 epsilon_value : 4.616 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 1700\t Average reward in last 100 episode : -412.80 epsilon_policy : 0.184 epsilon_value : 4.593 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 1800\t Average reward in last 100 episode : -409.39 epsilon_policy : 0.183 epsilon_value : 4.570 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 1900\t Average reward in last 100 episode : -407.07 epsilon_policy : 0.182 epsilon_value : 4.547 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2000\t Average reward in last 100 episode : -405.82 epsilon_policy : 0.181 epsilon_value : 4.524 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " score @ 996 = -0.46961486149962295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 2100\t Average reward in last 100 episode : -401.42 epsilon_policy : 0.180 epsilon_value : 4.502 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2200\t Average reward in last 100 episode : -400.88 epsilon_policy : 0.179 epsilon_value : 4.479 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2300\t Average reward in last 100 episode : -400.50 epsilon_policy : 0.178 epsilon_value : 4.457 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2400\t Average reward in last 100 episode : -398.07 epsilon_policy : 0.177 epsilon_value : 4.435 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2500\t Average reward in last 100 episode : -398.39 epsilon_policy : 0.176 epsilon_value : 4.412 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2600\t Average reward in last 100 episode : -396.22 epsilon_policy : 0.176 epsilon_value : 4.390 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2700\t Average reward in last 100 episode : -393.98 epsilon_policy : 0.175 epsilon_value : 4.369 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 2800\t Average reward in last 100 episode : -394.85 epsilon_policy : 0.174 epsilon_value : 4.347 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 2900\t Average reward in last 100 episode : -393.91 epsilon_policy : 0.173 epsilon_value : 4.325 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 3000\t Average reward in last 100 episode : -390.36 epsilon_policy : 0.172 epsilon_value : 4.304 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " score @ 1000 = -0.4123565170972133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 3100\t Average reward in last 100 episode : -389.95 epsilon_policy : 0.171 epsilon_value : 4.282 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 3200\t Average reward in last 100 episode : -387.80 epsilon_policy : 0.170 epsilon_value : 4.261 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 3300\t Average reward in last 100 episode : -386.62 epsilon_policy : 0.170 epsilon_value : 4.239 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3400\t Average reward in last 100 episode : -385.45 epsilon_policy : 0.169 epsilon_value : 4.218 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3500\t Average reward in last 100 episode : -385.12 epsilon_policy : 0.168 epsilon_value : 4.197 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3600\t Average reward in last 100 episode : -383.87 epsilon_policy : 0.167 epsilon_value : 4.176 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3700\t Average reward in last 100 episode : -382.84 epsilon_policy : 0.166 epsilon_value : 4.156 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3800\t Average reward in last 100 episode : -381.03 epsilon_policy : 0.165 epsilon_value : 4.135 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3900\t Average reward in last 100 episode : -380.01 epsilon_policy : 0.165 epsilon_value : 4.114 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4000\t Average reward in last 100 episode : -378.82 epsilon_policy : 0.164 epsilon_value : 4.094 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " score @ 995 = -0.39748263447204464"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 4100\t Average reward in last 100 episode : -377.25 epsilon_policy : 0.163 epsilon_value : 4.073 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4200\t Average reward in last 100 episode : -376.57 epsilon_policy : 0.162 epsilon_value : 4.053 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4300\t Average reward in last 100 episode : -376.42 epsilon_policy : 0.161 epsilon_value : 4.033 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4400\t Average reward in last 100 episode : -375.01 epsilon_policy : 0.161 epsilon_value : 4.013 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4500\t Average reward in last 100 episode : -374.44 epsilon_policy : 0.160 epsilon_value : 3.993 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4600\t Average reward in last 100 episode : -373.20 epsilon_policy : 0.159 epsilon_value : 3.973 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4700\t Average reward in last 100 episode : -372.52 epsilon_policy : 0.158 epsilon_value : 3.953 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4800\t Average reward in last 100 episode : -371.07 epsilon_policy : 0.157 epsilon_value : 3.933 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4900\t Average reward in last 100 episode : -369.79 epsilon_policy : 0.157 epsilon_value : 3.913 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 5000\t Average reward in last 100 episode : -369.25 epsilon_policy : 0.156 epsilon_value : 3.894 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " score @ 992 = -0.38016493308202136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 5100\t Average reward in last 100 episode : -369.52 epsilon_policy : 0.155 epsilon_value : 3.875 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5200\t Average reward in last 100 episode : -367.90 epsilon_policy : 0.154 epsilon_value : 3.855 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5300\t Average reward in last 100 episode : -366.47 epsilon_policy : 0.153 epsilon_value : 3.836 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5400\t Average reward in last 100 episode : -364.11 epsilon_policy : 0.153 epsilon_value : 3.817 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5500\t Average reward in last 100 episode : -363.12 epsilon_policy : 0.152 epsilon_value : 3.798 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5600\t Average reward in last 100 episode : -362.72 epsilon_policy : 0.151 epsilon_value : 3.779 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5700\t Average reward in last 100 episode : -362.68 epsilon_policy : 0.150 epsilon_value : 3.760 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5800\t Average reward in last 100 episode : -360.30 epsilon_policy : 0.150 epsilon_value : 3.741 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 5900\t Average reward in last 100 episode : -360.25 epsilon_policy : 0.149 epsilon_value : 3.723 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6000\t Average reward in last 100 episode : -359.88 epsilon_policy : 0.148 epsilon_value : 3.704 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " score @ 994 = -0.45195948273178144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 6100\t Average reward in last 100 episode : -356.67 epsilon_policy : 0.147 epsilon_value : 3.686 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6200\t Average reward in last 100 episode : -351.94 epsilon_policy : 0.147 epsilon_value : 3.667 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6300\t Average reward in last 100 episode : -344.01 epsilon_policy : 0.146 epsilon_value : 3.649 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6400\t Average reward in last 100 episode : -347.84 epsilon_policy : 0.145 epsilon_value : 3.631 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6500\t Average reward in last 100 episode : -340.64 epsilon_policy : 0.145 epsilon_value : 3.613 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 6600\t Average reward in last 100 episode : -336.23 epsilon_policy : 0.144 epsilon_value : 3.595 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 6700\t Average reward in last 100 episode : -335.15 epsilon_policy : 0.143 epsilon_value : 3.577 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 6800\t Average reward in last 100 episode : -332.54 epsilon_policy : 0.142 epsilon_value : 3.559 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 6900\t Average reward in last 100 episode : -327.45 epsilon_policy : 0.142 epsilon_value : 3.541 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7000\t Average reward in last 100 episode : -319.93 epsilon_policy : 0.141 epsilon_value : 3.523 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " score @ 996 = -0.37703663202021914"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 7100\t Average reward in last 100 episode : -319.48 epsilon_policy : 0.140 epsilon_value : 3.506 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7200\t Average reward in last 100 episode : -318.72 epsilon_policy : 0.140 epsilon_value : 3.488 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7300\t Average reward in last 100 episode : -313.38 epsilon_policy : 0.139 epsilon_value : 3.471 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7400\t Average reward in last 100 episode : -310.18 epsilon_policy : 0.138 epsilon_value : 3.454 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7500\t Average reward in last 100 episode : -307.99 epsilon_policy : 0.137 epsilon_value : 3.436 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7600\t Average reward in last 100 episode : -302.01 epsilon_policy : 0.137 epsilon_value : 3.419 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7700\t Average reward in last 100 episode : -300.13 epsilon_policy : 0.136 epsilon_value : 3.402 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7800\t Average reward in last 100 episode : -297.82 epsilon_policy : 0.135 epsilon_value : 3.385 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7900\t Average reward in last 100 episode : -294.73 epsilon_policy : 0.135 epsilon_value : 3.368 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8000\t Average reward in last 100 episode : -294.15 epsilon_policy : 0.134 epsilon_value : 3.352 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " score @ 1000 = -0.2932264354876613"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 8100\t Average reward in last 100 episode : -292.68 epsilon_policy : 0.133 epsilon_value : 3.335 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8200\t Average reward in last 100 episode : -290.32 epsilon_policy : 0.133 epsilon_value : 3.318 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8300\t Average reward in last 100 episode : -288.17 epsilon_policy : 0.132 epsilon_value : 3.302 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8400\t Average reward in last 100 episode : -287.96 epsilon_policy : 0.131 epsilon_value : 3.285 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8500\t Average reward in last 100 episode : -284.85 epsilon_policy : 0.131 epsilon_value : 3.269 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8600\t Average reward in last 100 episode : -282.84 epsilon_policy : 0.130 epsilon_value : 3.253 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8700\t Average reward in last 100 episode : -282.25 epsilon_policy : 0.129 epsilon_value : 3.236 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 8800\t Average reward in last 100 episode : -281.45 epsilon_policy : 0.129 epsilon_value : 3.220 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 8900\t Average reward in last 100 episode : -279.57 epsilon_policy : 0.128 epsilon_value : 3.204 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9000\t Average reward in last 100 episode : -278.40 epsilon_policy : 0.128 epsilon_value : 3.188 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " score @ 995 = -0.23638259066206974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 9100\t Average reward in last 100 episode : -277.82 epsilon_policy : 0.127 epsilon_value : 3.172 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9200\t Average reward in last 100 episode : -279.02 epsilon_policy : 0.126 epsilon_value : 3.156 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9300\t Average reward in last 100 episode : -277.08 epsilon_policy : 0.126 epsilon_value : 3.141 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9400\t Average reward in last 100 episode : -278.29 epsilon_policy : 0.125 epsilon_value : 3.125 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9500\t Average reward in last 100 episode : -274.29 epsilon_policy : 0.124 epsilon_value : 3.109 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9600\t Average reward in last 100 episode : -275.23 epsilon_policy : 0.124 epsilon_value : 3.094 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9700\t Average reward in last 100 episode : -275.03 epsilon_policy : 0.123 epsilon_value : 3.078 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9800\t Average reward in last 100 episode : -272.32 epsilon_policy : 0.123 epsilon_value : 3.063 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9900\t Average reward in last 100 episode : -272.41 epsilon_policy : 0.122 epsilon_value : 3.048 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 10000\t Average reward in last 100 episode : -272.16 epsilon_policy : 0.121 epsilon_value : 3.033 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " score @ 997 = -0.41820263712951514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 10100\t Average reward in last 100 episode : -271.69 epsilon_policy : 0.121 epsilon_value : 3.017 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 10200\t Average reward in last 100 episode : -272.51 epsilon_policy : 0.120 epsilon_value : 3.002 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 10300\t Average reward in last 100 episode : -270.43 epsilon_policy : 0.119 epsilon_value : 2.987 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 10400\t Average reward in last 100 episode : -271.29 epsilon_policy : 0.119 epsilon_value : 2.973 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 10500\t Average reward in last 100 episode : -268.84 epsilon_policy : 0.118 epsilon_value : 2.958 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 10600\t Average reward in last 100 episode : -267.36 epsilon_policy : 0.118 epsilon_value : 2.943 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 10700\t Average reward in last 100 episode : -267.62 epsilon_policy : 0.117 epsilon_value : 2.928 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 10800\t Average reward in last 100 episode : -266.51 epsilon_policy : 0.117 epsilon_value : 2.914 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 10900\t Average reward in last 100 episode : -265.39 epsilon_policy : 0.116 epsilon_value : 2.899 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 11000\t Average reward in last 100 episode : -265.15 epsilon_policy : 0.115 epsilon_value : 2.885 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " score @ 998 = -0.41638443762720513"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 11100\t Average reward in last 100 episode : -263.12 epsilon_policy : 0.115 epsilon_value : 2.870 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.006\n",
      " Episode : 11200\t Average reward in last 100 episode : -261.95 epsilon_policy : 0.114 epsilon_value : 2.856 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.006\n",
      " Episode : 11300\t Average reward in last 100 episode : -260.76 epsilon_policy : 0.114 epsilon_value : 2.842 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.006\n",
      " Episode : 11400\t Average reward in last 100 episode : -259.12 epsilon_policy : 0.113 epsilon_value : 2.828 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.006\n",
      " Episode : 11500\t Average reward in last 100 episode : -256.99 epsilon_policy : 0.113 epsilon_value : 2.813 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.006\n",
      " Episode : 11600\t Average reward in last 100 episode : -256.99 epsilon_policy : 0.112 epsilon_value : 2.799 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.006\n",
      " Episode : 11700\t Average reward in last 100 episode : -254.67 epsilon_policy : 0.111 epsilon_value : 2.785 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.006\n",
      " Episode : 11800\t Average reward in last 100 episode : -254.33 epsilon_policy : 0.111 epsilon_value : 2.772 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.006\n",
      " Episode : 11900\t Average reward in last 100 episode : -251.91 epsilon_policy : 0.110 epsilon_value : 2.758 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.006\n",
      " Episode : 12000\t Average reward in last 100 episode : -250.22 epsilon_policy : 0.110 epsilon_value : 2.744 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.005\n",
      " score @ 990 = -0.39031360909572316"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 12100\t Average reward in last 100 episode : -250.27 epsilon_policy : 0.109 epsilon_value : 2.730 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.005\n",
      " Episode : 12200\t Average reward in last 100 episode : -249.95 epsilon_policy : 0.109 epsilon_value : 2.717 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.005\n",
      " Episode : 12300\t Average reward in last 100 episode : -249.96 epsilon_policy : 0.108 epsilon_value : 2.703 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.005\n",
      " Episode : 12400\t Average reward in last 100 episode : -248.51 epsilon_policy : 0.108 epsilon_value : 2.690 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.005\n",
      " Episode : 12500\t Average reward in last 100 episode : -248.55 epsilon_policy : 0.107 epsilon_value : 2.676 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.005\n",
      " Episode : 12600\t Average reward in last 100 episode : -247.42 epsilon_policy : 0.107 epsilon_value : 2.663 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.005\n",
      " Episode : 12700\t Average reward in last 100 episode : -246.95 epsilon_policy : 0.106 epsilon_value : 2.650 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.005\n",
      " Episode : 12800\t Average reward in last 100 episode : -247.32 epsilon_policy : 0.105 epsilon_value : 2.636 lambda_gae : 0.800 gamma : 0.989 entropy_reg : 0.005\n",
      " Episode : 12900\t Average reward in last 100 episode : -247.48 epsilon_policy : 0.105 epsilon_value : 2.623 lambda_gae : 0.800 gamma : 0.990 entropy_reg : 0.005\n",
      " Episode : 13000\t Average reward in last 100 episode : -245.83 epsilon_policy : 0.104 epsilon_value : 2.610 lambda_gae : 0.800 gamma : 0.990 entropy_reg : 0.005\n",
      " score @ 995 = -0.33264712671777047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 13100\t Average reward in last 100 episode : -247.73 epsilon_policy : 0.104 epsilon_value : 2.597 lambda_gae : 0.800 gamma : 0.990 entropy_reg : 0.005\n",
      " Episode : 13200\t Average reward in last 100 episode : -252.49 epsilon_policy : 0.103 epsilon_value : 2.584 lambda_gae : 0.800 gamma : 0.990 entropy_reg : 0.005\n",
      " Episode : 13300\t Average reward in last 100 episode : -264.94 epsilon_policy : 0.103 epsilon_value : 2.571 lambda_gae : 0.800 gamma : 0.990 entropy_reg : 0.005\n",
      " Episode : 13400\t Average reward in last 100 episode : -258.09 epsilon_policy : 0.102 epsilon_value : 2.559 lambda_gae : 0.800 gamma : 0.990 entropy_reg : 0.005\n",
      " Episode : 13500\t Average reward in last 100 episode : -255.20 epsilon_policy : 0.102 epsilon_value : 2.546 lambda_gae : 0.800 gamma : 0.990 entropy_reg : 0.005\n",
      " Episode : 13600\t Average reward in last 100 episode : -253.55 epsilon_policy : 0.101 epsilon_value : 2.533 lambda_gae : 0.800 gamma : 0.990 entropy_reg : 0.005\n",
      " Episode : 13700\t Average reward in last 100 episode : -254.94 epsilon_policy : 0.101 epsilon_value : 2.520 lambda_gae : 0.800 gamma : 0.990 entropy_reg : 0.005\n",
      " Episode : 13800\t Average reward in last 100 episode : -257.12 epsilon_policy : 0.100 epsilon_value : 2.508 lambda_gae : 0.800 gamma : 0.990 entropy_reg : 0.005\n",
      " Episode : 13900\t Average reward in last 100 episode : -257.58 epsilon_policy : 0.100 epsilon_value : 2.495 lambda_gae : 0.800 gamma : 0.990 entropy_reg : 0.005\n",
      " Episode : 14000\t Average reward in last 100 episode : -258.51 epsilon_policy : 0.099 epsilon_value : 2.483 lambda_gae : 0.800 gamma : 0.990 entropy_reg : 0.005\n",
      " score @ 2 = -0.6178521928777748"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(policy_value_network\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m     16\u001b[0m a2c_agent \u001b[38;5;241m=\u001b[39m A2C_PPO_LOSS(policy_value_network,\n\u001b[1;32m     17\u001b[0m                  optimizer,\n\u001b[1;32m     18\u001b[0m                  value_loss_coef\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m                  action_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39mx,\n\u001b[1;32m     36\u001b[0m                  verbosity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[43ma2c_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl/policy_gradient_methods/a2c.py:235\u001b[0m, in \u001b[0;36mA2C_PPO_LOSS.training\u001b[0;34m(self, env, tmax, tmax_for_training, n_episodes)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m Episode : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Average reward in last \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m episode : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_of_last_x_episodes\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epsilon_policy : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon_policy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epsilon_value : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m lambda_gae : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlambda_gae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m gamma : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgamma\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m entropy_reg : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentropy_reg\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (e\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39m(\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity) \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m :\n\u001b[0;32m--> 235\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m avg_of_last_x_episodes \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_score:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnvironment solved in episodes = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/rl/example_solutions/example_environment_classes/gym_mujoco__parallel_env_class.py:43\u001b[0m, in \u001b[0;36mMujocoGymNumStateContActions.play\u001b[0;34m(self, agent, tmax)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mact(state)\n\u001b[0;32m---> 43\u001b[0m     nextstate, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (reward \u001b[38;5;241m-\u001b[39m score)\u001b[38;5;241m/\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m score @ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/wrappers/time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/pusher_v4.py:174\u001b[0m, in \u001b[0;36mPusherEnv.step\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_simulation(a, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_skip)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m ob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_obs()\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    178\u001b[0m     ob,\n\u001b[1;32m    179\u001b[0m     reward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mdict\u001b[39m(reward_dist\u001b[38;5;241m=\u001b[39mreward_dist, reward_ctrl\u001b[38;5;241m=\u001b[39mreward_ctrl),\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_env.py:379\u001b[0m, in \u001b[0;36mMujocoEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmujoco_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamera_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamera_name\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:673\u001b[0m, in \u001b[0;36mMujocoRenderer.render\u001b[0;34m(self, render_mode, camera_id, camera_name)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m render_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:402\u001b[0m, in \u001b[0;36mWindowViewer.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paused:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paused:\n\u001b[0;32m--> 402\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_advance_by_one_step:\n\u001b[1;32m    404\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_advance_by_one_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:353\u001b[0m, in \u001b[0;36mWindowViewer.render.<locals>.update\u001b[0;34m()\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m():\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;66;03m# fill overlay items\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_overlay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     render_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:588\u001b[0m, in \u001b[0;36mWindowViewer._create_overlay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_overlay(topleft, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCap[t]ure frame\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved as \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m fname)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_overlay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCap[t]ure frame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_overlay(topleft, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToggle geomgroup visibility\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0-4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_overlay(bottomleft, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFPS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_per_render, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from policy_gradient_methods.a2c import A2C_PPO_LOSS\n",
    "from policy_gradient_methods.utils import *\n",
    "from example_environment_classes.gym_mujoco__parallel_env_class import MujocoGymNumStateContActions\n",
    "from itertools import chain\n",
    "import torch.optim as optim\n",
    "learning_rate = 1e-3\n",
    "episode = 50000\n",
    "tmax = 1000\n",
    "state_dim = 23\n",
    "action_dim = 7\n",
    "envs = MujocoGymNumStateContActions(\"Pusher-v4\")\n",
    "# Initializing policy network, optimizer and agent\n",
    "device = get_device()\n",
    "policy_value_network = Policy_Value_Network(state_dim,action_dim).to(device)\n",
    "optimizer = optim.Adam(policy_value_network.parameters(), lr=learning_rate)\n",
    "a2c_agent = A2C_PPO_LOSS(policy_value_network,\n",
    "                 optimizer,\n",
    "                 value_loss_coef=1,\n",
    "                 n_boot_strap=1,\n",
    "                 normalize_advantage =True,\n",
    "                 use_gae_advantage = True,\n",
    "                 lambda_bootstrap_schedule = lambda old_value, rewards: old_value,\n",
    "                 lambda_bootstrap_start=0.8,\n",
    "                 ppo_value_epsilon_schedule = lambda old_value, rewards: max([0.99995*old_value, 0.5]),\n",
    "                 ppo_value_epsilon_start = 5,\n",
    "                 SGD_steps=4,\n",
    "                 ppo_policy_epsilon_schedule=lambda old_value, rewards: max([0.99995*old_value, 0.09]),\n",
    "                 ppo_policy_epsilon_start=0.2,\n",
    "                 entropy_reg_schedule = lambda old_value, rewards: 0.99995*old_value,\n",
    "                 entropy_reg_start=0.01,\n",
    "                 gamma_schedule = lambda old_value, rewards: 1.- 0.99995*(1. - old_value),\n",
    "                 gamma_start = 0.98,\n",
    "                 target_score=30,\n",
    "                 target_score_window=100,\n",
    "                 action_transform = lambda x: -2+4*x,\n",
    "                 verbosity = 100)\n",
    "a2c_agent.training(envs, tmax, tmax, episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f0eddeb-93fb-4fff-9a9d-d87e6d072b72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " score @ 753 = -0.33993789629339337"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x2905611b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/n0k03zp/Desktop/miniforge3/envs/pytorch_gpu_new/lib/python3.10/site-packages/glfw/__init__.py\", line 1275, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " score @ 1000 = -0.34106474172898965"
     ]
    }
   ],
   "source": [
    "envs.play(a2c_agent, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1880f513-0810-4a19-9307-bf816798114e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d5cf90a-5d89-460c-b958-ea851fd97d83",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 100\t Average reward in last 100 episode : -328.80 epsilon_policy : 0.199 epsilon_value : 4.975 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 200\t Average reward in last 100 episode : -311.16 epsilon_policy : 0.198 epsilon_value : 4.950 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 300\t Average reward in last 100 episode : -309.81 epsilon_policy : 0.197 epsilon_value : 4.926 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 400\t Average reward in last 100 episode : -309.39 epsilon_policy : 0.196 epsilon_value : 4.901 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 500\t Average reward in last 100 episode : -308.35 epsilon_policy : 0.195 epsilon_value : 4.877 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 600\t Average reward in last 100 episode : -307.80 epsilon_policy : 0.194 epsilon_value : 4.852 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 700\t Average reward in last 100 episode : -307.00 epsilon_policy : 0.193 epsilon_value : 4.828 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 800\t Average reward in last 100 episode : -306.03 epsilon_policy : 0.192 epsilon_value : 4.804 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 900\t Average reward in last 100 episode : -305.54 epsilon_policy : 0.191 epsilon_value : 4.780 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 1000\t Average reward in last 100 episode : -303.43 epsilon_policy : 0.190 epsilon_value : 4.756 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 1100\t Average reward in last 100 episode : -303.99 epsilon_policy : 0.189 epsilon_value : 4.732 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1200\t Average reward in last 100 episode : -302.08 epsilon_policy : 0.188 epsilon_value : 4.709 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1300\t Average reward in last 100 episode : -305.62 epsilon_policy : 0.187 epsilon_value : 4.685 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1400\t Average reward in last 100 episode : -301.85 epsilon_policy : 0.186 epsilon_value : 4.662 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1500\t Average reward in last 100 episode : -301.25 epsilon_policy : 0.186 epsilon_value : 4.639 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1600\t Average reward in last 100 episode : -298.39 epsilon_policy : 0.185 epsilon_value : 4.616 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 1700\t Average reward in last 100 episode : -295.99 epsilon_policy : 0.184 epsilon_value : 4.593 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 1800\t Average reward in last 100 episode : -295.62 epsilon_policy : 0.183 epsilon_value : 4.570 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 1900\t Average reward in last 100 episode : -292.00 epsilon_policy : 0.182 epsilon_value : 4.547 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2000\t Average reward in last 100 episode : -291.26 epsilon_policy : 0.181 epsilon_value : 4.524 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2100\t Average reward in last 100 episode : -287.03 epsilon_policy : 0.180 epsilon_value : 4.502 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2200\t Average reward in last 100 episode : -285.92 epsilon_policy : 0.179 epsilon_value : 4.479 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2300\t Average reward in last 100 episode : -282.45 epsilon_policy : 0.178 epsilon_value : 4.457 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2400\t Average reward in last 100 episode : -281.67 epsilon_policy : 0.177 epsilon_value : 4.435 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2500\t Average reward in last 100 episode : -279.72 epsilon_policy : 0.176 epsilon_value : 4.412 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2600\t Average reward in last 100 episode : -279.17 epsilon_policy : 0.176 epsilon_value : 4.390 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2700\t Average reward in last 100 episode : -277.26 epsilon_policy : 0.175 epsilon_value : 4.369 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 2800\t Average reward in last 100 episode : -278.04 epsilon_policy : 0.174 epsilon_value : 4.347 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 2900\t Average reward in last 100 episode : -276.46 epsilon_policy : 0.173 epsilon_value : 4.325 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 3000\t Average reward in last 100 episode : -274.36 epsilon_policy : 0.172 epsilon_value : 4.304 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 3100\t Average reward in last 100 episode : -273.12 epsilon_policy : 0.171 epsilon_value : 4.282 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 3200\t Average reward in last 100 episode : -271.46 epsilon_policy : 0.170 epsilon_value : 4.261 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 3300\t Average reward in last 100 episode : -270.82 epsilon_policy : 0.170 epsilon_value : 4.239 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3400\t Average reward in last 100 episode : -269.99 epsilon_policy : 0.169 epsilon_value : 4.218 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3500\t Average reward in last 100 episode : -270.31 epsilon_policy : 0.168 epsilon_value : 4.197 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3600\t Average reward in last 100 episode : -270.52 epsilon_policy : 0.167 epsilon_value : 4.176 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3700\t Average reward in last 100 episode : -268.56 epsilon_policy : 0.166 epsilon_value : 4.156 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3800\t Average reward in last 100 episode : -268.03 epsilon_policy : 0.165 epsilon_value : 4.135 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3900\t Average reward in last 100 episode : -267.22 epsilon_policy : 0.165 epsilon_value : 4.114 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4000\t Average reward in last 100 episode : -268.68 epsilon_policy : 0.164 epsilon_value : 4.094 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4100\t Average reward in last 100 episode : -266.56 epsilon_policy : 0.163 epsilon_value : 4.073 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4200\t Average reward in last 100 episode : -266.58 epsilon_policy : 0.162 epsilon_value : 4.053 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4300\t Average reward in last 100 episode : -266.66 epsilon_policy : 0.161 epsilon_value : 4.033 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4400\t Average reward in last 100 episode : -267.81 epsilon_policy : 0.161 epsilon_value : 4.013 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4500\t Average reward in last 100 episode : -267.46 epsilon_policy : 0.160 epsilon_value : 3.993 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4600\t Average reward in last 100 episode : -266.55 epsilon_policy : 0.159 epsilon_value : 3.973 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4700\t Average reward in last 100 episode : -263.77 epsilon_policy : 0.158 epsilon_value : 3.953 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4800\t Average reward in last 100 episode : -262.75 epsilon_policy : 0.157 epsilon_value : 3.933 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4900\t Average reward in last 100 episode : -263.26 epsilon_policy : 0.157 epsilon_value : 3.913 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 5000\t Average reward in last 100 episode : -263.48 epsilon_policy : 0.156 epsilon_value : 3.894 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 5100\t Average reward in last 100 episode : -262.77 epsilon_policy : 0.155 epsilon_value : 3.875 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5200\t Average reward in last 100 episode : -263.01 epsilon_policy : 0.154 epsilon_value : 3.855 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5300\t Average reward in last 100 episode : -260.98 epsilon_policy : 0.153 epsilon_value : 3.836 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5400\t Average reward in last 100 episode : -261.71 epsilon_policy : 0.153 epsilon_value : 3.817 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5500\t Average reward in last 100 episode : -261.57 epsilon_policy : 0.152 epsilon_value : 3.798 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5600\t Average reward in last 100 episode : -260.08 epsilon_policy : 0.151 epsilon_value : 3.779 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5700\t Average reward in last 100 episode : -259.27 epsilon_policy : 0.150 epsilon_value : 3.760 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5800\t Average reward in last 100 episode : -259.49 epsilon_policy : 0.150 epsilon_value : 3.741 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 5900\t Average reward in last 100 episode : -262.08 epsilon_policy : 0.149 epsilon_value : 3.723 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6000\t Average reward in last 100 episode : -260.44 epsilon_policy : 0.148 epsilon_value : 3.704 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6100\t Average reward in last 100 episode : -259.80 epsilon_policy : 0.147 epsilon_value : 3.686 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6200\t Average reward in last 100 episode : -259.15 epsilon_policy : 0.147 epsilon_value : 3.667 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6300\t Average reward in last 100 episode : -259.52 epsilon_policy : 0.146 epsilon_value : 3.649 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6400\t Average reward in last 100 episode : -258.95 epsilon_policy : 0.145 epsilon_value : 3.631 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6500\t Average reward in last 100 episode : -258.04 epsilon_policy : 0.145 epsilon_value : 3.613 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 6600\t Average reward in last 100 episode : -256.89 epsilon_policy : 0.144 epsilon_value : 3.595 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 6700\t Average reward in last 100 episode : -257.35 epsilon_policy : 0.143 epsilon_value : 3.577 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 6800\t Average reward in last 100 episode : -255.89 epsilon_policy : 0.142 epsilon_value : 3.559 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 6900\t Average reward in last 100 episode : -256.28 epsilon_policy : 0.142 epsilon_value : 3.541 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7000\t Average reward in last 100 episode : -255.14 epsilon_policy : 0.141 epsilon_value : 3.523 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7100\t Average reward in last 100 episode : -252.73 epsilon_policy : 0.140 epsilon_value : 3.506 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7200\t Average reward in last 100 episode : -253.50 epsilon_policy : 0.140 epsilon_value : 3.488 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7300\t Average reward in last 100 episode : -252.29 epsilon_policy : 0.139 epsilon_value : 3.471 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7400\t Average reward in last 100 episode : -251.40 epsilon_policy : 0.138 epsilon_value : 3.454 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7500\t Average reward in last 100 episode : -250.11 epsilon_policy : 0.137 epsilon_value : 3.436 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7600\t Average reward in last 100 episode : -249.02 epsilon_policy : 0.137 epsilon_value : 3.419 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7700\t Average reward in last 100 episode : -250.48 epsilon_policy : 0.136 epsilon_value : 3.402 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7800\t Average reward in last 100 episode : -250.77 epsilon_policy : 0.135 epsilon_value : 3.385 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7900\t Average reward in last 100 episode : -251.28 epsilon_policy : 0.135 epsilon_value : 3.368 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8000\t Average reward in last 100 episode : -250.10 epsilon_policy : 0.134 epsilon_value : 3.352 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8100\t Average reward in last 100 episode : -250.69 epsilon_policy : 0.133 epsilon_value : 3.335 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8200\t Average reward in last 100 episode : -250.52 epsilon_policy : 0.133 epsilon_value : 3.318 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8300\t Average reward in last 100 episode : -250.82 epsilon_policy : 0.132 epsilon_value : 3.302 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8400\t Average reward in last 100 episode : -250.95 epsilon_policy : 0.131 epsilon_value : 3.285 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8500\t Average reward in last 100 episode : -252.37 epsilon_policy : 0.131 epsilon_value : 3.269 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8600\t Average reward in last 100 episode : -250.89 epsilon_policy : 0.130 epsilon_value : 3.253 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8700\t Average reward in last 100 episode : -254.80 epsilon_policy : 0.129 epsilon_value : 3.236 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 8800\t Average reward in last 100 episode : -253.61 epsilon_policy : 0.129 epsilon_value : 3.220 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 8900\t Average reward in last 100 episode : -252.40 epsilon_policy : 0.128 epsilon_value : 3.204 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9000\t Average reward in last 100 episode : -250.40 epsilon_policy : 0.128 epsilon_value : 3.188 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9100\t Average reward in last 100 episode : -249.29 epsilon_policy : 0.127 epsilon_value : 3.172 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9200\t Average reward in last 100 episode : -250.45 epsilon_policy : 0.126 epsilon_value : 3.156 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9300\t Average reward in last 100 episode : -250.11 epsilon_policy : 0.126 epsilon_value : 3.141 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9400\t Average reward in last 100 episode : -250.76 epsilon_policy : 0.125 epsilon_value : 3.125 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9500\t Average reward in last 100 episode : -252.15 epsilon_policy : 0.124 epsilon_value : 3.109 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9600\t Average reward in last 100 episode : -250.17 epsilon_policy : 0.124 epsilon_value : 3.094 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9700\t Average reward in last 100 episode : -250.98 epsilon_policy : 0.123 epsilon_value : 3.078 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9800\t Average reward in last 100 episode : -253.52 epsilon_policy : 0.123 epsilon_value : 3.063 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9900\t Average reward in last 100 episode : -257.81 epsilon_policy : 0.122 epsilon_value : 3.048 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 10000\t Average reward in last 100 episode : -253.68 epsilon_policy : 0.121 epsilon_value : 3.033 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-296.9234784709758,\n",
       " -400.46394295433913,\n",
       " -400.7080396022728,\n",
       " -317.4329907809552,\n",
       " -328.96252517209325,\n",
       " -382.2226581908077,\n",
       " -374.15204912713597,\n",
       " -368.42989119772454,\n",
       " -387.2265764207591,\n",
       " -384.4576092382939,\n",
       " -387.7910533662056,\n",
       " -386.3246051962454,\n",
       " -373.4410190527371,\n",
       " -356.0001653344516,\n",
       " -332.359945532805,\n",
       " -331.7752479094123,\n",
       " -329.34951808060515,\n",
       " -333.2104122910326,\n",
       " -351.07067118259096,\n",
       " -351.5305428349222,\n",
       " -348.18957020652147,\n",
       " -350.65704657666606,\n",
       " -351.3596865200628,\n",
       " -351.8630747296008,\n",
       " -349.94971864829415,\n",
       " -348.34686611433153,\n",
       " -340.3286220052238,\n",
       " -342.2053345367949,\n",
       " -336.11269859771085,\n",
       " -335.81904611192977,\n",
       " -335.4284082456419,\n",
       " -331.19593462939645,\n",
       " -329.08247412793105,\n",
       " -329.6506847902705,\n",
       " -329.9929406307623,\n",
       " -328.3445604885002,\n",
       " -332.1970695863291,\n",
       " -328.8525833854061,\n",
       " -319.0317491356744,\n",
       " -315.5063592897976,\n",
       " -327.08381705764384,\n",
       " -329.7390571969096,\n",
       " -326.07652115437395,\n",
       " -324.0821753178042,\n",
       " -326.041206156529,\n",
       " -336.6165765570181,\n",
       " -325.50939432817876,\n",
       " -324.470803156899,\n",
       " -324.4995676306031,\n",
       " -327.0926794614787,\n",
       " -320.3332956406651,\n",
       " -322.59853605918704,\n",
       " -318.36622304984473,\n",
       " -323.44372083280547,\n",
       " -325.09064833029026,\n",
       " -321.52233629538625,\n",
       " -321.8614827090535,\n",
       " -325.25953110880346,\n",
       " -314.26403167479964,\n",
       " -317.49579989045776,\n",
       " -312.9485151113525,\n",
       " -311.2771330796395,\n",
       " -310.7103227974699,\n",
       " -310.5681617267467,\n",
       " -311.7925495841188,\n",
       " -308.3971293108449,\n",
       " -311.49852715055977,\n",
       " -315.6435022292353,\n",
       " -320.4954155065662,\n",
       " -307.82961562397196,\n",
       " -313.8599132991973,\n",
       " -313.1729280579564,\n",
       " -304.6046567656822,\n",
       " -316.3939398666088,\n",
       " -305.0592192747328,\n",
       " -315.5072042981118,\n",
       " -315.43378613215936,\n",
       " -318.7162408100017,\n",
       " -316.03364259231,\n",
       " -309.55147840642616,\n",
       " -310.2548603187768,\n",
       " -312.2524128234438,\n",
       " -316.42623433694007,\n",
       " -312.3331858965312,\n",
       " -317.53824609000515,\n",
       " -317.5048377553808,\n",
       " -305.0540509428173,\n",
       " -312.11933866622957,\n",
       " -309.87146243078627,\n",
       " -307.21935291536477,\n",
       " -307.54651806141953,\n",
       " -312.1151892792974,\n",
       " -310.0788238475694,\n",
       " -318.604114802781,\n",
       " -313.741928454452,\n",
       " -314.72652278668585,\n",
       " -316.6419365738037,\n",
       " -304.91583196635213,\n",
       " -312.7137748817272,\n",
       " -309.56745701507776,\n",
       " -307.6889921835782,\n",
       " -310.1923484048456,\n",
       " -320.8391048453024,\n",
       " -306.16275967736834,\n",
       " -315.23727876745915,\n",
       " -310.5476880810508,\n",
       " -320.35052516591,\n",
       " -314.6349168612708,\n",
       " -315.9836016446176,\n",
       " -309.6562898982569,\n",
       " -305.6036083465398,\n",
       " -315.1652276562115,\n",
       " -303.8235440897876,\n",
       " -304.3034465643999,\n",
       " -313.69959505652065,\n",
       " -311.40929801925404,\n",
       " -307.95179297208693,\n",
       " -314.08308755564786,\n",
       " -316.18130769030756,\n",
       " -311.249955460754,\n",
       " -314.6736153900589,\n",
       " -318.6995017857061,\n",
       " -311.31098128422485,\n",
       " -311.0036542262603,\n",
       " -318.40420276502425,\n",
       " -313.7995351020178,\n",
       " -306.92249074892914,\n",
       " -312.7241334653119,\n",
       " -316.4597457517268,\n",
       " -303.7528936082375,\n",
       " -312.8407737008747,\n",
       " -312.7817724101705,\n",
       " -310.1789970005184,\n",
       " -317.6938749626698,\n",
       " -307.8728353945208,\n",
       " -309.97031270252046,\n",
       " -314.5362722922352,\n",
       " -309.472968167126,\n",
       " -312.8335871714038,\n",
       " -309.8737870644296,\n",
       " -309.71124985001427,\n",
       " -310.47050243027024,\n",
       " -305.00247308577235,\n",
       " -309.5202308090711,\n",
       " -318.4602840540522,\n",
       " -308.5880091917189,\n",
       " -311.5812847150952,\n",
       " -313.8774749780206,\n",
       " -308.7337225687653,\n",
       " -307.5581111409848,\n",
       " -314.04970063687125,\n",
       " -309.6265795866907,\n",
       " -306.92932054425523,\n",
       " -309.39749975415975,\n",
       " -305.12267744725176,\n",
       " -313.1685471159293,\n",
       " -305.77540700070006,\n",
       " -313.5327296101767,\n",
       " -314.3379761967893,\n",
       " -307.25001795055704,\n",
       " -315.48541026186587,\n",
       " -319.04651237146,\n",
       " -316.22463680649867,\n",
       " -306.4051178341068,\n",
       " -313.00364489541136,\n",
       " -301.9454846479137,\n",
       " -309.285797287818,\n",
       " -311.52396958922543,\n",
       " -306.9735547040227,\n",
       " -308.0676119054752,\n",
       " -304.24628078874247,\n",
       " -309.2624816265429,\n",
       " -311.05559095985916,\n",
       " -308.2497514619846,\n",
       " -311.75721273944595,\n",
       " -309.47249025184874,\n",
       " -317.3676646123489,\n",
       " -314.8488644441988,\n",
       " -311.3480848879554,\n",
       " -310.10678805174666,\n",
       " -308.9707230011355,\n",
       " -313.0152241342488,\n",
       " -310.1896970497099,\n",
       " -310.9078412683918,\n",
       " -306.23516258080826,\n",
       " -302.3511951173152,\n",
       " -314.4165884575027,\n",
       " -306.687018578761,\n",
       " -311.8574555278636,\n",
       " -318.18909879222946,\n",
       " -306.5666258190224,\n",
       " -314.30118444659837,\n",
       " -314.4954551227311,\n",
       " -317.3820506126357,\n",
       " -313.5079721605431,\n",
       " -310.328801826058,\n",
       " -314.7591908723577,\n",
       " -309.7676385051146,\n",
       " -303.6446801061179,\n",
       " -309.0418497623931,\n",
       " -307.5587545041192,\n",
       " -306.453251742277,\n",
       " -307.4190825526975,\n",
       " -306.63111572588184,\n",
       " -309.283974126874,\n",
       " -307.79938002810104,\n",
       " -308.67426351039524,\n",
       " -310.57917736919427,\n",
       " -310.47706359307506,\n",
       " -320.20986028396925,\n",
       " -307.2751034855504,\n",
       " -316.30547071930334,\n",
       " -312.8273385578915,\n",
       " -307.4654271394812,\n",
       " -308.46247171141306,\n",
       " -315.9027411423907,\n",
       " -311.56432089283186,\n",
       " -305.33091007144907,\n",
       " -310.70746451590446,\n",
       " -307.2399664081145,\n",
       " -307.3884501254129,\n",
       " -306.40378680979904,\n",
       " -309.2749894192099,\n",
       " -312.20078138744526,\n",
       " -305.76980792477724,\n",
       " -310.92086621839996,\n",
       " -312.6542360933679,\n",
       " -316.51104313077457,\n",
       " -312.410146004632,\n",
       " -315.2165728829223,\n",
       " -314.09191572782476,\n",
       " -308.991626125295,\n",
       " -310.11959067828764,\n",
       " -304.9684442779876,\n",
       " -312.4958151784548,\n",
       " -314.99382513709793,\n",
       " -310.20993337707296,\n",
       " -314.16227670998387,\n",
       " -304.02517857369537,\n",
       " -313.98516938097686,\n",
       " -309.54999360562164,\n",
       " -310.4501471848676,\n",
       " -308.2583259947786,\n",
       " -310.1684178204408,\n",
       " -302.89182375207645,\n",
       " -310.75433060023397,\n",
       " -308.49866022405365,\n",
       " -317.31338206825626,\n",
       " -310.739516450937,\n",
       " -307.24607865763613,\n",
       " -311.97893416470674,\n",
       " -307.79023718005607,\n",
       " -308.09500278785697,\n",
       " -318.93422746559605,\n",
       " -307.12649723198456,\n",
       " -302.22440483097176,\n",
       " -309.6959259846507,\n",
       " -305.3343825289997,\n",
       " -311.4225507716566,\n",
       " -311.95744760165724,\n",
       " -306.0762797931044,\n",
       " -308.26173646289783,\n",
       " -307.2718421142138,\n",
       " -308.553717306438,\n",
       " -313.15340940301445,\n",
       " -318.92038461266816,\n",
       " -304.8072346359675,\n",
       " -308.51213808992304,\n",
       " -314.73512213933213,\n",
       " -315.7947783453664,\n",
       " -310.33890946089446,\n",
       " -319.64831042256833,\n",
       " -309.0245990092839,\n",
       " -308.3438067896533,\n",
       " -307.13881020394956,\n",
       " -310.2136614274588,\n",
       " -307.769112071871,\n",
       " -303.6658225189664,\n",
       " -314.080006186217,\n",
       " -306.0981763494548,\n",
       " -311.72458335306715,\n",
       " -312.13779109998853,\n",
       " -305.96858434651534,\n",
       " -307.1409171289322,\n",
       " -315.71898289480345,\n",
       " -309.8867370918274,\n",
       " -303.0493327517216,\n",
       " -308.0899525357237,\n",
       " -313.37142294140847,\n",
       " -307.3714354266452,\n",
       " -308.0062474424606,\n",
       " -302.3808242967268,\n",
       " -306.7500157665587,\n",
       " -304.5586748316461,\n",
       " -311.40792741581055,\n",
       " -308.61126060892997,\n",
       " -313.4716936026228,\n",
       " -305.22352909305425,\n",
       " -308.39495440444233,\n",
       " -310.37950457875763,\n",
       " -308.03985319186046,\n",
       " -309.80399054650013,\n",
       " -309.0577337959245,\n",
       " -314.52547913966987,\n",
       " -311.8167527279362,\n",
       " -307.97476704836515,\n",
       " -310.1169126003691,\n",
       " -313.4029737572003,\n",
       " -309.53523756999346,\n",
       " -307.98931879563617,\n",
       " -304.6089311835025,\n",
       " -304.68324724675244,\n",
       " -310.2652032716756,\n",
       " -308.1937335767781,\n",
       " -306.9407757940027,\n",
       " -303.70315252701323,\n",
       " -306.84440354962373,\n",
       " -310.532965113171,\n",
       " -308.9282051632158,\n",
       " -305.20269258527554,\n",
       " -314.46368850090363,\n",
       " -303.45255476723327,\n",
       " -307.4818150601574,\n",
       " -314.1892542447545,\n",
       " -312.075280464288,\n",
       " -308.5298733038174,\n",
       " -319.25547397177615,\n",
       " -302.5553012153763,\n",
       " -315.742566030342,\n",
       " -305.9163484668185,\n",
       " -309.9174296300107,\n",
       " -308.7965356949091,\n",
       " -311.11213558750876,\n",
       " -303.6456850539356,\n",
       " -319.5110147334563,\n",
       " -305.74720444198203,\n",
       " -307.2007181814477,\n",
       " -309.122992458372,\n",
       " -305.41487075532916,\n",
       " -307.7395198066441,\n",
       " -309.9426427955338,\n",
       " -312.88943498405007,\n",
       " -307.7479649987587,\n",
       " -303.52796661426544,\n",
       " -317.0188313768118,\n",
       " -308.3049643755632,\n",
       " -315.4651017118772,\n",
       " -310.40939654125793,\n",
       " -309.4378596661352,\n",
       " -314.444187782905,\n",
       " -315.02102944807615,\n",
       " -303.91369119682406,\n",
       " -309.8739656646103,\n",
       " -309.7275612502427,\n",
       " -312.1307171703257,\n",
       " -311.94123380391477,\n",
       " -312.271770250059,\n",
       " -307.14793394052566,\n",
       " -309.1148142819535,\n",
       " -308.96420533484707,\n",
       " -313.97637440729807,\n",
       " -311.34458038395434,\n",
       " -314.5718966003809,\n",
       " -303.21897543468697,\n",
       " -307.99744804922227,\n",
       " -304.7031974217923,\n",
       " -302.120358739538,\n",
       " -312.7850827303679,\n",
       " -307.54047656805716,\n",
       " -319.1791362840364,\n",
       " -309.1486978067623,\n",
       " -304.6955000171746,\n",
       " -311.86990702324266,\n",
       " -313.05435682342716,\n",
       " -317.78724148042704,\n",
       " -311.25798681138946,\n",
       " -308.7702427297369,\n",
       " -306.38104307239325,\n",
       " -308.3218926615144,\n",
       " -305.7869271233659,\n",
       " -308.16583755615954,\n",
       " -303.67898081667533,\n",
       " -306.3491748928272,\n",
       " -302.3290189396798,\n",
       " -307.0125973142643,\n",
       " -307.05371914675595,\n",
       " -303.3146289711729,\n",
       " -307.9332325973428,\n",
       " -308.84480831245725,\n",
       " -310.58156522387844,\n",
       " -311.4571005307029,\n",
       " -312.0989844314063,\n",
       " -311.29106932579344,\n",
       " -314.12766151456066,\n",
       " -310.9250708014163,\n",
       " -305.8494405383038,\n",
       " -313.3913602360198,\n",
       " -307.74263879846677,\n",
       " -311.1630248996146,\n",
       " -307.9091481703329,\n",
       " -304.57575824670977,\n",
       " -309.3292470130938,\n",
       " -314.32675903976804,\n",
       " -302.4975273025048,\n",
       " -311.05330535219764,\n",
       " -306.9356454978514,\n",
       " -307.42365555165014,\n",
       " -316.39248031196763,\n",
       " -303.23601254459606,\n",
       " -314.7029591378337,\n",
       " -306.38609604133507,\n",
       " -306.1848431324021,\n",
       " -313.2798752745566,\n",
       " -303.5760365771466,\n",
       " -298.3313434528911,\n",
       " -301.1789571625249,\n",
       " -309.76336368375553,\n",
       " -312.22017550569143,\n",
       " -307.8710925196887,\n",
       " -309.6450613318499,\n",
       " -311.5936743549295,\n",
       " -309.1243993986692,\n",
       " -315.64971035753786,\n",
       " -318.46754721074905,\n",
       " -311.0572543661629,\n",
       " -316.1341190159641,\n",
       " -312.8287395994575,\n",
       " -301.8694077734068,\n",
       " -307.8383546662034,\n",
       " -301.3278607382071,\n",
       " -306.1082186611541,\n",
       " -308.83609335881863,\n",
       " -305.69673314025687,\n",
       " -307.37621122033045,\n",
       " -308.65982919939427,\n",
       " -304.1728143078532,\n",
       " -307.99205901929673,\n",
       " -307.64238247423475,\n",
       " -318.14435390416463,\n",
       " -315.2301993625064,\n",
       " -306.0463482842114,\n",
       " -303.93941318381667,\n",
       " -306.0917207682184,\n",
       " -304.3496015242792,\n",
       " -304.8384486158468,\n",
       " -305.69700131118424,\n",
       " -304.99178108423223,\n",
       " -311.34593414689164,\n",
       " -309.72878002735587,\n",
       " -304.61631989534084,\n",
       " -313.5948059845508,\n",
       " -300.84479682251333,\n",
       " -308.83155465355213,\n",
       " -305.59350811391516,\n",
       " -308.5898081766071,\n",
       " -314.36805107929615,\n",
       " -307.5971523708736,\n",
       " -303.6846893105139,\n",
       " -307.49248986330974,\n",
       " -303.73154489925565,\n",
       " -307.46433740523696,\n",
       " -300.3233406442453,\n",
       " -306.2811550740605,\n",
       " -312.822858920512,\n",
       " -316.4443621492936,\n",
       " -308.317665902017,\n",
       " -314.1667798591801,\n",
       " -305.65746692970254,\n",
       " -305.52427688184196,\n",
       " -321.50847745259017,\n",
       " -305.8866575962439,\n",
       " -310.3210444265552,\n",
       " -309.88201318902424,\n",
       " -302.84070767243577,\n",
       " -310.933635548624,\n",
       " -301.3579263379861,\n",
       " -298.2350022685427,\n",
       " -316.86939243712646,\n",
       " -310.87335290039437,\n",
       " -310.3534333307541,\n",
       " -315.4767715609736,\n",
       " -307.8258342440551,\n",
       " -313.0234681107474,\n",
       " -303.8186859491428,\n",
       " -313.1285245356786,\n",
       " -306.1429526600238,\n",
       " -309.99790434768727,\n",
       " -303.7188027821367,\n",
       " -309.61686580434935,\n",
       " -315.5008895754869,\n",
       " -300.176075467399,\n",
       " -306.16098445462603,\n",
       " -310.82852598674975,\n",
       " -299.72908585257665,\n",
       " -308.3104806267809,\n",
       " -308.2810362969825,\n",
       " -301.9122043988517,\n",
       " -313.86504177409125,\n",
       " -313.92726244999096,\n",
       " -306.4796417227777,\n",
       " -302.54871698285604,\n",
       " -305.71556004425247,\n",
       " -309.1381606325534,\n",
       " -313.67193000971645,\n",
       " -307.6024164870495,\n",
       " -305.8531644838949,\n",
       " -310.9943572161166,\n",
       " -301.0772765410653,\n",
       " -311.5101732650859,\n",
       " -306.53125629400375,\n",
       " -303.97713186426114,\n",
       " -308.54429417942816,\n",
       " -302.6499645022785,\n",
       " -300.3078498019762,\n",
       " -312.1353889328551,\n",
       " -299.0728037631536,\n",
       " -313.23170338559066,\n",
       " -300.9689545959193,\n",
       " -310.7676047056196,\n",
       " -309.8477562066903,\n",
       " -309.824895193943,\n",
       " -310.48809949216337,\n",
       " -304.1556005054196,\n",
       " -300.6020194628469,\n",
       " -306.9821727122377,\n",
       " -306.67002616001855,\n",
       " -304.4091353793063,\n",
       " -306.68977919080385,\n",
       " -309.2413221032015,\n",
       " -304.6351929533722,\n",
       " -304.20642013511207,\n",
       " -304.83008676474003,\n",
       " -310.5321693734986,\n",
       " -308.37510161389133,\n",
       " -312.2957659590395,\n",
       " -310.7885883929571,\n",
       " -303.038083886783,\n",
       " -309.8315111670353,\n",
       " -303.43078965021067,\n",
       " -315.36270638023865,\n",
       " -308.2581935179239,\n",
       " -311.4270544425976,\n",
       " -305.5871775717287,\n",
       " -313.1859726417593,\n",
       " -313.57376361685704,\n",
       " -310.8196679686761,\n",
       " -310.89945856337033,\n",
       " -305.6972505701607,\n",
       " -312.74526277258286,\n",
       " -300.9541832005069,\n",
       " -307.6469961345791,\n",
       " -321.8212979343067,\n",
       " -308.03145423388344,\n",
       " -317.2023686228257,\n",
       " -306.9643177020926,\n",
       " -310.826900228185,\n",
       " -307.72940042405867,\n",
       " -309.886195948512,\n",
       " -321.70032207607534,\n",
       " -306.34319177818907,\n",
       " -320.14953497370675,\n",
       " -300.50732450894265,\n",
       " -316.2995797799642,\n",
       " -305.8618330965377,\n",
       " -302.83303539894024,\n",
       " -307.30085279436696,\n",
       " -303.05944520989743,\n",
       " -300.4024879080243,\n",
       " -305.3943725558869,\n",
       " -303.93217880602,\n",
       " -307.6673602156576,\n",
       " -305.61932424779786,\n",
       " -305.8164716998699,\n",
       " -316.11357631166004,\n",
       " -300.7273784600601,\n",
       " -308.17110243008716,\n",
       " -307.60845251075244,\n",
       " -309.10832942485735,\n",
       " -302.85269304956995,\n",
       " -305.3984755066224,\n",
       " -301.1680739918043,\n",
       " -315.42725711002066,\n",
       " -302.8425516902985,\n",
       " -309.5314398243311,\n",
       " -314.1245207041373,\n",
       " -301.94791457843417,\n",
       " -309.7524142596911,\n",
       " -307.3732330707406,\n",
       " -306.9067296847097,\n",
       " -310.11346541692035,\n",
       " -306.111090824411,\n",
       " -310.2490096354269,\n",
       " -313.2957566205596,\n",
       " -316.5640522796776,\n",
       " -305.3798373999542,\n",
       " -302.53896155778466,\n",
       " -301.698816686155,\n",
       " -306.5232364773043,\n",
       " -307.8231174903145,\n",
       " -302.0135876197901,\n",
       " -301.0789382691388,\n",
       " -314.59927310277044,\n",
       " -306.585250373381,\n",
       " -313.3560177159601,\n",
       " -302.2053609479948,\n",
       " -310.0493860234071,\n",
       " -308.43776324832504,\n",
       " -303.48916689775217,\n",
       " -315.69992835091296,\n",
       " -306.0040792287017,\n",
       " -311.98656605227313,\n",
       " -298.8987605369199,\n",
       " -305.34228206834234,\n",
       " -316.0166525345767,\n",
       " -309.14784749744473,\n",
       " -318.92485744145836,\n",
       " -305.81035529906416,\n",
       " -316.9907968229538,\n",
       " -310.79175688031086,\n",
       " -309.953848516597,\n",
       " -312.31998682174344,\n",
       " -305.4616879228537,\n",
       " -312.2245686706248,\n",
       " -312.6428681609949,\n",
       " -311.28113723707014,\n",
       " -303.5029671780386,\n",
       " -305.10775597263813,\n",
       " -311.6914107634413,\n",
       " -310.4721893857311,\n",
       " -307.28755200544924,\n",
       " -302.3751993557514,\n",
       " -306.8399537193926,\n",
       " -298.892019767927,\n",
       " -303.80575030558083,\n",
       " -300.42335879082873,\n",
       " -308.46107045371366,\n",
       " -303.6356593378133,\n",
       " -303.3249914464327,\n",
       " -299.5093101334418,\n",
       " -304.9664514391971,\n",
       " -303.63043083111063,\n",
       " -310.08208537602513,\n",
       " -299.0910910138062,\n",
       " -304.80141987724585,\n",
       " -305.49593193349074,\n",
       " -307.2513542748855,\n",
       " -309.80368389543804,\n",
       " -307.37866754248114,\n",
       " -302.2885732951212,\n",
       " -302.5586681891364,\n",
       " -314.2948839995676,\n",
       " -308.7261681778711,\n",
       " -308.55577775533703,\n",
       " -304.1584175324714,\n",
       " -310.394898572089,\n",
       " -314.4380356852631,\n",
       " -319.24423009067914,\n",
       " -308.9981566187339,\n",
       " -310.36565846615355,\n",
       " -310.21047041158533,\n",
       " -306.9179997819754,\n",
       " -306.6090809557094,\n",
       " -306.2942039527478,\n",
       " -308.58259269505277,\n",
       " -304.86394787341794,\n",
       " -308.75821769552107,\n",
       " -302.67713148597517,\n",
       " -314.14873582278403,\n",
       " -300.1891187800305,\n",
       " -311.72249633115416,\n",
       " -300.03146867369855,\n",
       " -294.10833283543195,\n",
       " -304.4697276354393,\n",
       " -301.5505202012657,\n",
       " -312.9988019935621,\n",
       " -314.0775229229028,\n",
       " -306.1255327135239,\n",
       " -312.3957236177629,\n",
       " -306.2797360182454,\n",
       " -313.1601712170126,\n",
       " -306.401401076547,\n",
       " -302.34362048048797,\n",
       " -302.3608806915745,\n",
       " -305.05181880542,\n",
       " -306.9505043369885,\n",
       " -306.256473856791,\n",
       " -307.4390683618678,\n",
       " -305.0304979454514,\n",
       " -303.03677767469173,\n",
       " -303.3572046953607,\n",
       " -302.52169491381073,\n",
       " -300.51434258874747,\n",
       " -301.4457958846659,\n",
       " -309.9662880199854,\n",
       " -299.92099100877033,\n",
       " -308.36611317731723,\n",
       " -310.3676490168165,\n",
       " -304.7718548098402,\n",
       " -304.5101995499877,\n",
       " -301.8973839500251,\n",
       " -301.4030979352091,\n",
       " -305.67941181332543,\n",
       " -307.3196614913463,\n",
       " -306.5052950687537,\n",
       " -299.81071783051084,\n",
       " -306.3037749739025,\n",
       " -297.8088203687367,\n",
       " -306.01131609557126,\n",
       " -311.56225902712015,\n",
       " -312.5258492092477,\n",
       " -316.16804098992475,\n",
       " -308.5934016844122,\n",
       " -308.5179082392516,\n",
       " -300.7983794723117,\n",
       " -299.1531222103899,\n",
       " -306.86158870937675,\n",
       " -294.2403787817144,\n",
       " -301.1667183872138,\n",
       " -315.0893081733978,\n",
       " -302.5738915068836,\n",
       " -318.35319672637877,\n",
       " -296.30552859464285,\n",
       " -309.184178455252,\n",
       " -305.20503116355945,\n",
       " -306.0160539326885,\n",
       " -311.6276716702462,\n",
       " -303.8499474908396,\n",
       " -302.8769478016968,\n",
       " -306.2920662529344,\n",
       " -298.3742001690204,\n",
       " -302.67380508758004,\n",
       " -309.14833070171824,\n",
       " -306.12837485725373,\n",
       " -305.09709254257996,\n",
       " -301.39301817096344,\n",
       " -305.7313112111009,\n",
       " -305.5081024848042,\n",
       " -301.7094306062249,\n",
       " -313.05428050505753,\n",
       " -305.50890201183387,\n",
       " -311.33211549168874,\n",
       " -304.2709267172442,\n",
       " -305.1200819725652,\n",
       " -314.988552005784,\n",
       " -297.8969205890971,\n",
       " -307.66928695912327,\n",
       " -305.54657396773496,\n",
       " -307.65374708737926,\n",
       " -308.06950667794024,\n",
       " -302.02730214211977,\n",
       " -315.7822060875762,\n",
       " -304.24290305003854,\n",
       " -317.4947212548723,\n",
       " -306.6597814020803,\n",
       " -306.81670828738913,\n",
       " -307.72343825281234,\n",
       " -299.2347409099697,\n",
       " -320.00435626719343,\n",
       " -299.8577050259311,\n",
       " -314.4702508705856,\n",
       " -303.77016180224325,\n",
       " -303.43790461362636,\n",
       " -307.12485981810516,\n",
       " -303.8846744040174,\n",
       " -315.2461141923751,\n",
       " -307.8034985779805,\n",
       " -313.13919791868705,\n",
       " -307.2569072389024,\n",
       " -302.3282566426322,\n",
       " -307.00001289565074,\n",
       " -299.0566974989949,\n",
       " -303.9673422349169,\n",
       " -309.87983823548814,\n",
       " -300.9711928056162,\n",
       " -310.54646542630155,\n",
       " -298.42651031171647,\n",
       " -308.6509327314784,\n",
       " -305.9790939766002,\n",
       " -298.83856452124496,\n",
       " -307.3859951855011,\n",
       " -305.18010726567684,\n",
       " -304.6552777743417,\n",
       " -309.39513434810044,\n",
       " -302.4232155942962,\n",
       " -311.49535480410515,\n",
       " -305.15408163235844,\n",
       " -308.38576757235217,\n",
       " -302.5169013380902,\n",
       " -299.8368944013979,\n",
       " -303.425362974211,\n",
       " -302.5820439625011,\n",
       " -303.02348476137365,\n",
       " -304.710931641915,\n",
       " -306.48805000990217,\n",
       " -300.93931819671593,\n",
       " -314.72592779864124,\n",
       " -300.3433255020595,\n",
       " -307.91495224721547,\n",
       " -308.1897826285707,\n",
       " -307.7465141335718,\n",
       " -305.65349334097857,\n",
       " -301.5721916333629,\n",
       " -308.8385822410449,\n",
       " -305.1622573642477,\n",
       " -307.5108274872212,\n",
       " -309.7251592983309,\n",
       " -298.08156632273233,\n",
       " -304.74020714676516,\n",
       " -305.393210866285,\n",
       " -301.4463850305884,\n",
       " -304.5838273814767,\n",
       " -304.85449272410835,\n",
       " -304.0306462789892,\n",
       " -316.27349103261923,\n",
       " -291.6850088758774,\n",
       " -303.950874862726,\n",
       " -306.24564436051827,\n",
       " -302.41644874845764,\n",
       " -305.1496143426717,\n",
       " -299.6995689178541,\n",
       " -306.23799482646615,\n",
       " -300.6877615912362,\n",
       " -307.3839423399819,\n",
       " -299.7542624624237,\n",
       " -308.2316401467805,\n",
       " -304.67188235140895,\n",
       " -308.2387809067542,\n",
       " -308.25020182277,\n",
       " -310.7887890073338,\n",
       " -312.11669635572713,\n",
       " -304.96137678686097,\n",
       " -312.4119653726867,\n",
       " -305.0881668744879,\n",
       " -309.3989421585742,\n",
       " -312.60613297549384,\n",
       " -306.13352534708264,\n",
       " -303.605722417262,\n",
       " -316.79647441065197,\n",
       " -299.64107224786073,\n",
       " -311.59915752344057,\n",
       " -295.7211606172769,\n",
       " -308.40476081892496,\n",
       " -304.1691774430793,\n",
       " -300.94834979467095,\n",
       " -307.1739478538759,\n",
       " -298.5511187680049,\n",
       " -307.07928431387165,\n",
       " -310.4086247743253,\n",
       " -297.18702192280955,\n",
       " -320.07124346464474,\n",
       " -311.7388998546318,\n",
       " -320.4569915176903,\n",
       " -302.13977471424806,\n",
       " -298.00384339568444,\n",
       " -306.8553421109188,\n",
       " -293.8774226017692,\n",
       " -304.176853370858,\n",
       " -311.74913724613265,\n",
       " -295.0153016333578,\n",
       " -308.4486683127474,\n",
       " -305.8525438122271,\n",
       " -301.0451262737223,\n",
       " -304.6615012009538,\n",
       " -308.1665327023674,\n",
       " -310.2734519931356,\n",
       " -307.1305616201703,\n",
       " -298.87881227982905,\n",
       " -310.5770810317829,\n",
       " -305.4769266220152,\n",
       " -306.5933443413392,\n",
       " -304.9108630708475,\n",
       " -301.56748620196106,\n",
       " -303.4368170756881,\n",
       " -306.615219117032,\n",
       " -301.3722530016588,\n",
       " -304.2377084975466,\n",
       " -308.6856775005488,\n",
       " -307.7703380856375,\n",
       " -308.21747737439097,\n",
       " -298.67138515700793,\n",
       " -307.8457886417853,\n",
       " -302.63540278837553,\n",
       " -304.8662757528261,\n",
       " -307.63221745598923,\n",
       " -306.19825819858244,\n",
       " -313.312808671485,\n",
       " -303.27864183689866,\n",
       " -310.8259212949749,\n",
       " -306.49565468960566,\n",
       " -309.7675102351311,\n",
       " -301.11335272707504,\n",
       " -309.77808066074755,\n",
       " -299.5246406860436,\n",
       " -306.65002091962316,\n",
       " -304.2583726426505,\n",
       " -300.1719502856821,\n",
       " -301.39050727839424,\n",
       " -308.28017940633515,\n",
       " -300.15649149857813,\n",
       " -307.5594604207728,\n",
       " -303.9672701854811,\n",
       " -300.93621919479364,\n",
       " -307.2683815802821,\n",
       " -301.2132672935119,\n",
       " -300.45265095018397,\n",
       " -307.834367427855,\n",
       " -302.28932514743127,\n",
       " -301.0349667463189,\n",
       " -294.6652540186127,\n",
       " -302.8889126795155,\n",
       " -304.3144274472444,\n",
       " -299.38461969594346,\n",
       " -307.12139543743746,\n",
       " -302.4480161632202,\n",
       " -302.482701432095,\n",
       " -306.0456934245441,\n",
       " -299.6150125640463,\n",
       " -301.23247925739275,\n",
       " -309.17750068416206,\n",
       " -298.42247727438445,\n",
       " -301.0789171930366,\n",
       " -297.88613645052726,\n",
       " -303.3372292712617,\n",
       " -298.4443600688817,\n",
       " -304.64635626935836,\n",
       " -304.35986868541465,\n",
       " -301.7939565846599,\n",
       " -314.2368663529275,\n",
       " -295.72671538643993,\n",
       " -314.0827348598997,\n",
       " -305.7019984696791,\n",
       " -302.44072680025664,\n",
       " -312.55640087749873,\n",
       " -303.75373510541465,\n",
       " -308.7579377965374,\n",
       " -302.44011879457,\n",
       " -302.14308639230006,\n",
       " -301.5000104246209,\n",
       " -302.0283576542847,\n",
       " -303.4932878924128,\n",
       " -299.4844259716277,\n",
       " -303.2909767975921,\n",
       " -304.4634959439391,\n",
       " -301.2590293665818,\n",
       " -298.01145246308135,\n",
       " -303.22811926225734,\n",
       " -300.12023315864167,\n",
       " -300.1575782127612,\n",
       " -305.9578361475397,\n",
       " -301.7412688046202,\n",
       " -299.7852761996522,\n",
       " -309.4797985171669,\n",
       " -308.8038796474859,\n",
       " -299.9976772857932,\n",
       " -313.05875743284844,\n",
       " -300.7051277648923,\n",
       " -313.51129871598295,\n",
       " -304.1033758330301,\n",
       " -304.6444198928588,\n",
       " -306.33211647382063,\n",
       " -306.5285561173234,\n",
       " -303.67597751902144,\n",
       " -310.10778962839856,\n",
       " -303.4525038345732,\n",
       " -301.7744296625509,\n",
       " -301.53857396647015,\n",
       " -304.9854391051592,\n",
       " -305.5615485038265,\n",
       " -302.44432734171727,\n",
       " -301.9615328023948,\n",
       " -303.9067805669387,\n",
       " -303.4780853654833,\n",
       " -298.30256839992956,\n",
       " -307.4081946425129,\n",
       " -310.275728612648,\n",
       " -300.3287322801749,\n",
       " -306.8576467513945,\n",
       " -302.45933192760515,\n",
       " -299.67120122785235,\n",
       " -303.46712744166047,\n",
       " -293.39224930343624,\n",
       " -309.91815094256583,\n",
       " -301.3921398299986,\n",
       " -299.35302502613246,\n",
       " -302.34375158868863,\n",
       " -298.8309004489114,\n",
       " -300.7704072755412,\n",
       " -310.03880723190093,\n",
       " -303.4437851425615,\n",
       " -307.0937971454609,\n",
       " -302.5578567998527,\n",
       " -309.7658953746562,\n",
       " -303.0549925111594,\n",
       " -295.63334120933735,\n",
       " -305.00608354451936,\n",
       " -301.0278188156921,\n",
       " -303.8739946502516,\n",
       " -299.74269428418677,\n",
       " -300.8609475200801,\n",
       " -305.8411677129751,\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_agent.training(envs, tmax, tmax, episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7072fdb2-2144-4a79-a691-fcba9b69600b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 100\t Average reward in last 100 episode : -415.18 epsilon_policy : 0.199 epsilon_value : 4.975 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 200\t Average reward in last 100 episode : -381.43 epsilon_policy : 0.198 epsilon_value : 4.950 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 300\t Average reward in last 100 episode : -375.86 epsilon_policy : 0.197 epsilon_value : 4.926 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 400\t Average reward in last 100 episode : -361.22 epsilon_policy : 0.196 epsilon_value : 4.901 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 500\t Average reward in last 100 episode : -354.39 epsilon_policy : 0.195 epsilon_value : 4.877 lambda_gae : 0.800 gamma : 0.980 entropy_reg : 0.010\n",
      " Episode : 600\t Average reward in last 100 episode : -361.15 epsilon_policy : 0.194 epsilon_value : 4.852 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 700\t Average reward in last 100 episode : -362.10 epsilon_policy : 0.193 epsilon_value : 4.828 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 800\t Average reward in last 100 episode : -353.03 epsilon_policy : 0.192 epsilon_value : 4.804 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 900\t Average reward in last 100 episode : -339.14 epsilon_policy : 0.191 epsilon_value : 4.780 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 1000\t Average reward in last 100 episode : -334.62 epsilon_policy : 0.190 epsilon_value : 4.756 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.010\n",
      " Episode : 1100\t Average reward in last 100 episode : -363.38 epsilon_policy : 0.189 epsilon_value : 4.732 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1200\t Average reward in last 100 episode : -377.23 epsilon_policy : 0.188 epsilon_value : 4.709 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1300\t Average reward in last 100 episode : -359.43 epsilon_policy : 0.187 epsilon_value : 4.685 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1400\t Average reward in last 100 episode : -345.52 epsilon_policy : 0.186 epsilon_value : 4.662 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1500\t Average reward in last 100 episode : -340.10 epsilon_policy : 0.186 epsilon_value : 4.639 lambda_gae : 0.800 gamma : 0.981 entropy_reg : 0.009\n",
      " Episode : 1600\t Average reward in last 100 episode : -338.85 epsilon_policy : 0.185 epsilon_value : 4.616 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 1700\t Average reward in last 100 episode : -337.06 epsilon_policy : 0.184 epsilon_value : 4.593 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 1800\t Average reward in last 100 episode : -325.85 epsilon_policy : 0.183 epsilon_value : 4.570 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 1900\t Average reward in last 100 episode : -325.06 epsilon_policy : 0.182 epsilon_value : 4.547 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2000\t Average reward in last 100 episode : -319.77 epsilon_policy : 0.181 epsilon_value : 4.524 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2100\t Average reward in last 100 episode : -315.68 epsilon_policy : 0.180 epsilon_value : 4.502 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2200\t Average reward in last 100 episode : -315.76 epsilon_policy : 0.179 epsilon_value : 4.479 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2300\t Average reward in last 100 episode : -317.71 epsilon_policy : 0.178 epsilon_value : 4.457 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2400\t Average reward in last 100 episode : -315.43 epsilon_policy : 0.177 epsilon_value : 4.435 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2500\t Average reward in last 100 episode : -313.38 epsilon_policy : 0.176 epsilon_value : 4.412 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2600\t Average reward in last 100 episode : -310.26 epsilon_policy : 0.176 epsilon_value : 4.390 lambda_gae : 0.800 gamma : 0.982 entropy_reg : 0.009\n",
      " Episode : 2700\t Average reward in last 100 episode : -309.54 epsilon_policy : 0.175 epsilon_value : 4.369 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 2800\t Average reward in last 100 episode : -306.88 epsilon_policy : 0.174 epsilon_value : 4.347 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 2900\t Average reward in last 100 episode : -306.21 epsilon_policy : 0.173 epsilon_value : 4.325 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 3000\t Average reward in last 100 episode : -302.13 epsilon_policy : 0.172 epsilon_value : 4.304 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 3100\t Average reward in last 100 episode : -298.07 epsilon_policy : 0.171 epsilon_value : 4.282 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 3200\t Average reward in last 100 episode : -297.85 epsilon_policy : 0.170 epsilon_value : 4.261 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.009\n",
      " Episode : 3300\t Average reward in last 100 episode : -293.77 epsilon_policy : 0.170 epsilon_value : 4.239 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3400\t Average reward in last 100 episode : -292.89 epsilon_policy : 0.169 epsilon_value : 4.218 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3500\t Average reward in last 100 episode : -291.08 epsilon_policy : 0.168 epsilon_value : 4.197 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3600\t Average reward in last 100 episode : -291.07 epsilon_policy : 0.167 epsilon_value : 4.176 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3700\t Average reward in last 100 episode : -289.76 epsilon_policy : 0.166 epsilon_value : 4.156 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3800\t Average reward in last 100 episode : -293.11 epsilon_policy : 0.165 epsilon_value : 4.135 lambda_gae : 0.800 gamma : 0.983 entropy_reg : 0.008\n",
      " Episode : 3900\t Average reward in last 100 episode : -294.10 epsilon_policy : 0.165 epsilon_value : 4.114 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4000\t Average reward in last 100 episode : -290.75 epsilon_policy : 0.164 epsilon_value : 4.094 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4100\t Average reward in last 100 episode : -289.16 epsilon_policy : 0.163 epsilon_value : 4.073 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4200\t Average reward in last 100 episode : -285.94 epsilon_policy : 0.162 epsilon_value : 4.053 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4300\t Average reward in last 100 episode : -286.72 epsilon_policy : 0.161 epsilon_value : 4.033 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4400\t Average reward in last 100 episode : -285.55 epsilon_policy : 0.161 epsilon_value : 4.013 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4500\t Average reward in last 100 episode : -285.10 epsilon_policy : 0.160 epsilon_value : 3.993 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4600\t Average reward in last 100 episode : -282.57 epsilon_policy : 0.159 epsilon_value : 3.973 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4700\t Average reward in last 100 episode : -281.40 epsilon_policy : 0.158 epsilon_value : 3.953 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4800\t Average reward in last 100 episode : -280.40 epsilon_policy : 0.157 epsilon_value : 3.933 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 4900\t Average reward in last 100 episode : -276.82 epsilon_policy : 0.157 epsilon_value : 3.913 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 5000\t Average reward in last 100 episode : -276.42 epsilon_policy : 0.156 epsilon_value : 3.894 lambda_gae : 0.800 gamma : 0.984 entropy_reg : 0.008\n",
      " Episode : 5100\t Average reward in last 100 episode : -270.37 epsilon_policy : 0.155 epsilon_value : 3.875 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5200\t Average reward in last 100 episode : -268.90 epsilon_policy : 0.154 epsilon_value : 3.855 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5300\t Average reward in last 100 episode : -266.92 epsilon_policy : 0.153 epsilon_value : 3.836 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5400\t Average reward in last 100 episode : -268.62 epsilon_policy : 0.153 epsilon_value : 3.817 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5500\t Average reward in last 100 episode : -270.90 epsilon_policy : 0.152 epsilon_value : 3.798 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5600\t Average reward in last 100 episode : -267.63 epsilon_policy : 0.151 epsilon_value : 3.779 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5700\t Average reward in last 100 episode : -268.76 epsilon_policy : 0.150 epsilon_value : 3.760 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.008\n",
      " Episode : 5800\t Average reward in last 100 episode : -268.88 epsilon_policy : 0.150 epsilon_value : 3.741 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 5900\t Average reward in last 100 episode : -267.35 epsilon_policy : 0.149 epsilon_value : 3.723 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6000\t Average reward in last 100 episode : -267.50 epsilon_policy : 0.148 epsilon_value : 3.704 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6100\t Average reward in last 100 episode : -274.08 epsilon_policy : 0.147 epsilon_value : 3.686 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6200\t Average reward in last 100 episode : -278.93 epsilon_policy : 0.147 epsilon_value : 3.667 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6300\t Average reward in last 100 episode : -275.69 epsilon_policy : 0.146 epsilon_value : 3.649 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6400\t Average reward in last 100 episode : -267.13 epsilon_policy : 0.145 epsilon_value : 3.631 lambda_gae : 0.800 gamma : 0.985 entropy_reg : 0.007\n",
      " Episode : 6500\t Average reward in last 100 episode : -265.91 epsilon_policy : 0.145 epsilon_value : 3.613 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 6600\t Average reward in last 100 episode : -262.90 epsilon_policy : 0.144 epsilon_value : 3.595 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 6700\t Average reward in last 100 episode : -270.40 epsilon_policy : 0.143 epsilon_value : 3.577 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 6800\t Average reward in last 100 episode : -272.75 epsilon_policy : 0.142 epsilon_value : 3.559 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 6900\t Average reward in last 100 episode : -267.72 epsilon_policy : 0.142 epsilon_value : 3.541 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7000\t Average reward in last 100 episode : -260.23 epsilon_policy : 0.141 epsilon_value : 3.523 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7100\t Average reward in last 100 episode : -285.53 epsilon_policy : 0.140 epsilon_value : 3.506 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7200\t Average reward in last 100 episode : -317.45 epsilon_policy : 0.140 epsilon_value : 3.488 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7300\t Average reward in last 100 episode : -299.10 epsilon_policy : 0.139 epsilon_value : 3.471 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7400\t Average reward in last 100 episode : -314.24 epsilon_policy : 0.138 epsilon_value : 3.454 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7500\t Average reward in last 100 episode : -315.71 epsilon_policy : 0.137 epsilon_value : 3.436 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7600\t Average reward in last 100 episode : -318.86 epsilon_policy : 0.137 epsilon_value : 3.419 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7700\t Average reward in last 100 episode : -302.79 epsilon_policy : 0.136 epsilon_value : 3.402 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7800\t Average reward in last 100 episode : -295.48 epsilon_policy : 0.135 epsilon_value : 3.385 lambda_gae : 0.800 gamma : 0.986 entropy_reg : 0.007\n",
      " Episode : 7900\t Average reward in last 100 episode : -298.14 epsilon_policy : 0.135 epsilon_value : 3.368 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8000\t Average reward in last 100 episode : -299.42 epsilon_policy : 0.134 epsilon_value : 3.352 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8100\t Average reward in last 100 episode : -284.17 epsilon_policy : 0.133 epsilon_value : 3.335 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8200\t Average reward in last 100 episode : -275.48 epsilon_policy : 0.133 epsilon_value : 3.318 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8300\t Average reward in last 100 episode : -272.59 epsilon_policy : 0.132 epsilon_value : 3.302 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8400\t Average reward in last 100 episode : -268.09 epsilon_policy : 0.131 epsilon_value : 3.285 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8500\t Average reward in last 100 episode : -266.33 epsilon_policy : 0.131 epsilon_value : 3.269 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8600\t Average reward in last 100 episode : -263.38 epsilon_policy : 0.130 epsilon_value : 3.253 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.007\n",
      " Episode : 8700\t Average reward in last 100 episode : -262.30 epsilon_policy : 0.129 epsilon_value : 3.236 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 8800\t Average reward in last 100 episode : -260.19 epsilon_policy : 0.129 epsilon_value : 3.220 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 8900\t Average reward in last 100 episode : -258.84 epsilon_policy : 0.128 epsilon_value : 3.204 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9000\t Average reward in last 100 episode : -256.49 epsilon_policy : 0.128 epsilon_value : 3.188 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9100\t Average reward in last 100 episode : -256.59 epsilon_policy : 0.127 epsilon_value : 3.172 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9200\t Average reward in last 100 episode : -255.18 epsilon_policy : 0.126 epsilon_value : 3.156 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9300\t Average reward in last 100 episode : -255.19 epsilon_policy : 0.126 epsilon_value : 3.141 lambda_gae : 0.800 gamma : 0.987 entropy_reg : 0.006\n",
      " Episode : 9400\t Average reward in last 100 episode : -257.04 epsilon_policy : 0.125 epsilon_value : 3.125 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9500\t Average reward in last 100 episode : -258.23 epsilon_policy : 0.124 epsilon_value : 3.109 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9600\t Average reward in last 100 episode : -258.42 epsilon_policy : 0.124 epsilon_value : 3.094 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9700\t Average reward in last 100 episode : -259.40 epsilon_policy : 0.123 epsilon_value : 3.078 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9800\t Average reward in last 100 episode : -270.32 epsilon_policy : 0.123 epsilon_value : 3.063 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 9900\t Average reward in last 100 episode : -263.39 epsilon_policy : 0.122 epsilon_value : 3.048 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n",
      " Episode : 10000\t Average reward in last 100 episode : -263.42 epsilon_policy : 0.121 epsilon_value : 3.033 lambda_gae : 0.800 gamma : 0.988 entropy_reg : 0.006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-249.23601440553472,\n",
       " -346.61331909803374,\n",
       " -384.52839997658987,\n",
       " -394.9442950660782,\n",
       " -398.5608627236187,\n",
       " -410.71615876500357,\n",
       " -408.81551900602983,\n",
       " -400.9584474273284,\n",
       " -395.6041600477537,\n",
       " -382.85615387078167,\n",
       " -376.4305070115186,\n",
       " -375.6380417938102,\n",
       " -374.5426940627618,\n",
       " -368.6592143404672,\n",
       " -368.8749403454509,\n",
       " -378.25072836801894,\n",
       " -376.8688790860177,\n",
       " -368.62277124496666,\n",
       " -369.6554778833573,\n",
       " -371.5313830779135,\n",
       " -380.6668401167014,\n",
       " -376.8169394265509,\n",
       " -373.5910840793752,\n",
       " -381.1387118129261,\n",
       " -381.82639022770275,\n",
       " -384.7544461139568,\n",
       " -386.4354461418528,\n",
       " -392.06109331459527,\n",
       " -393.56833526867933,\n",
       " -393.1152001050818,\n",
       " -388.85223916037955,\n",
       " -391.34890089586366,\n",
       " -400.94471706936605,\n",
       " -395.73412402241746,\n",
       " -397.48934635077137,\n",
       " -397.2787859421688,\n",
       " -398.7944025657371,\n",
       " -401.52388691454837,\n",
       " -409.3779402137136,\n",
       " -400.8518818599865,\n",
       " -398.5519820355765,\n",
       " -396.0846799322952,\n",
       " -408.0313624906463,\n",
       " -396.9063571213031,\n",
       " -395.68614150124125,\n",
       " -406.31789240283683,\n",
       " -399.5287443188778,\n",
       " -399.9862182871868,\n",
       " -404.7932766399628,\n",
       " -409.27113668990194,\n",
       " -411.922098383935,\n",
       " -412.58883062342903,\n",
       " -416.71905226371416,\n",
       " -416.2356014918886,\n",
       " -415.33490711130133,\n",
       " -423.7548008693637,\n",
       " -433.5912057200163,\n",
       " -427.8857764777017,\n",
       " -425.2054637059665,\n",
       " -435.37929086527663,\n",
       " -430.23067834136344,\n",
       " -430.4576948322923,\n",
       " -426.7545679234544,\n",
       " -434.17262286670865,\n",
       " -430.9647058028453,\n",
       " -436.116553100045,\n",
       " -434.5408661262385,\n",
       " -437.07633542363567,\n",
       " -436.0476277740314,\n",
       " -431.98715359885625,\n",
       " -434.2193033754851,\n",
       " -431.0086044369261,\n",
       " -435.79889472902386,\n",
       " -435.0030628430603,\n",
       " -434.61196303861004,\n",
       " -434.2479814093158,\n",
       " -436.58791603817156,\n",
       " -438.957425029121,\n",
       " -441.26492087912965,\n",
       " -444.8125176411084,\n",
       " -452.96708811873276,\n",
       " -453.8792939611709,\n",
       " -460.81592683377767,\n",
       " -458.8074463833983,\n",
       " -458.88296987025615,\n",
       " -466.83463855824346,\n",
       " -471.6148435954734,\n",
       " -465.14284277004924,\n",
       " -477.00472012816715,\n",
       " -474.45344961244956,\n",
       " -475.3391358156535,\n",
       " -465.60983793023854,\n",
       " -470.49032665077283,\n",
       " -468.31574194094327,\n",
       " -460.0572789195,\n",
       " -463.44468868626336,\n",
       " -459.42110755599276,\n",
       " -456.43456862017365,\n",
       " -458.63142077631875,\n",
       " -443.0873039569868,\n",
       " -447.9145661648921,\n",
       " -438.78950915788573,\n",
       " -428.6431190796462,\n",
       " -436.4730671658184,\n",
       " -422.75735019816227,\n",
       " -428.6757288336841,\n",
       " -429.4544805532223,\n",
       " -423.74787967328746,\n",
       " -420.095995778612,\n",
       " -424.0826480025309,\n",
       " -418.4346099348033,\n",
       " -414.0132796285916,\n",
       " -410.2434381012258,\n",
       " -415.2229818596221,\n",
       " -408.3015272052595,\n",
       " -406.41774866102713,\n",
       " -400.052545918179,\n",
       " -401.69118933489233,\n",
       " -403.89845275259506,\n",
       " -391.66454256534485,\n",
       " -386.0823857518441,\n",
       " -387.7867919424449,\n",
       " -379.0323372472102,\n",
       " -379.97503858190345,\n",
       " -379.7797543561125,\n",
       " -381.85096297045664,\n",
       " -385.98234031035685,\n",
       " -380.6940016028127,\n",
       " -376.9103848152662,\n",
       " -378.1696853556437,\n",
       " -387.58893580663005,\n",
       " -388.5316216553568,\n",
       " -380.0219651821666,\n",
       " -385.77797762620514,\n",
       " -388.275720102004,\n",
       " -386.6073845219725,\n",
       " -390.9065662729487,\n",
       " -387.04687884666316,\n",
       " -384.65262318805753,\n",
       " -388.9596178961176,\n",
       " -389.7323957099065,\n",
       " -391.27395194785134,\n",
       " -389.4005256264601,\n",
       " -388.05667733993016,\n",
       " -383.58989080738274,\n",
       " -382.41258509773326,\n",
       " -383.19776955922725,\n",
       " -383.4813137865714,\n",
       " -382.21170303095784,\n",
       " -383.2552095549016,\n",
       " -379.77048342527246,\n",
       " -370.8595377800884,\n",
       " -382.17312386327865,\n",
       " -374.3797499748866,\n",
       " -380.7598687030562,\n",
       " -378.69016384542715,\n",
       " -379.5811924197859,\n",
       " -374.9253931187757,\n",
       " -369.89986337621394,\n",
       " -373.7774359560487,\n",
       " -370.3245320636255,\n",
       " -370.1205377651368,\n",
       " -367.52089510326243,\n",
       " -362.55815936860427,\n",
       " -367.2164457643205,\n",
       " -362.71918450615,\n",
       " -366.3829311745054,\n",
       " -359.65062930285524,\n",
       " -355.1278286141191,\n",
       " -358.89223372871345,\n",
       " -359.3494315041044,\n",
       " -358.11479813879765,\n",
       " -358.2083073914487,\n",
       " -355.71087814935606,\n",
       " -361.42724407313244,\n",
       " -354.4451046318844,\n",
       " -361.02280758956994,\n",
       " -354.84667996808935,\n",
       " -359.5552869292878,\n",
       " -355.7450022699631,\n",
       " -354.6247927699182,\n",
       " -360.77085843534053,\n",
       " -360.7614443794827,\n",
       " -359.1687626402143,\n",
       " -354.6471270065871,\n",
       " -359.75758475342417,\n",
       " -358.87387556641295,\n",
       " -358.1819619048395,\n",
       " -363.0240179993653,\n",
       " -359.2540270674691,\n",
       " -359.948853799827,\n",
       " -359.6158848616557,\n",
       " -362.4606399256682,\n",
       " -364.2783636107124,\n",
       " -362.9948113546908,\n",
       " -364.4861124513236,\n",
       " -368.4206447715119,\n",
       " -371.1139114951104,\n",
       " -367.7898425235149,\n",
       " -377.16072323611036,\n",
       " -368.9676204029241,\n",
       " -375.21583163504454,\n",
       " -371.86411500848305,\n",
       " -376.0192906538749,\n",
       " -378.1169974865179,\n",
       " -377.01491315972066,\n",
       " -382.16283361459466,\n",
       " -374.9362082544502,\n",
       " -380.48486513628995,\n",
       " -380.8899321980974,\n",
       " -378.02971742980975,\n",
       " -379.1632892368857,\n",
       " -377.92090178870467,\n",
       " -372.73406926126574,\n",
       " -373.2059601665712,\n",
       " -373.69828166285254,\n",
       " -374.467924697088,\n",
       " -375.86691905013265,\n",
       " -380.49963696274625,\n",
       " -377.2122925506431,\n",
       " -378.4369643488038,\n",
       " -376.5587631290268,\n",
       " -377.27564546478266,\n",
       " -372.6947516617694,\n",
       " -387.63373087478993,\n",
       " -381.7316314485446,\n",
       " -382.1431994742195,\n",
       " -392.7658709671599,\n",
       " -391.0595837798218,\n",
       " -388.0103866905728,\n",
       " -390.6777985481911,\n",
       " -385.5609962316497,\n",
       " -386.63218529720564,\n",
       " -387.08879520955725,\n",
       " -389.95508678196813,\n",
       " -383.14544749957537,\n",
       " -387.1599653541828,\n",
       " -385.97710357135,\n",
       " -388.89247033547565,\n",
       " -381.01288859911136,\n",
       " -383.81765668061047,\n",
       " -379.6516473645243,\n",
       " -381.7458951861648,\n",
       " -380.1671174667085,\n",
       " -378.00250220243754,\n",
       " -367.85668771849316,\n",
       " -374.5062131212067,\n",
       " -373.04641705702187,\n",
       " -375.42869648901126,\n",
       " -372.57340582655814,\n",
       " -369.4875652953945,\n",
       " -365.6541548633652,\n",
       " -371.82190323551464,\n",
       " -368.08282937542793,\n",
       " -371.5511615567092,\n",
       " -368.9146658276188,\n",
       " -367.86258402724354,\n",
       " -366.83073225022434,\n",
       " -368.8194151415675,\n",
       " -365.24234115646624,\n",
       " -370.58321323085477,\n",
       " -377.00250736191606,\n",
       " -371.48079404684023,\n",
       " -362.21599371137796,\n",
       " -379.684778869394,\n",
       " -382.64393708142717,\n",
       " -381.5955483435213,\n",
       " -376.84937630590883,\n",
       " -377.4619986094395,\n",
       " -385.6789033981965,\n",
       " -385.15325441889837,\n",
       " -382.6527630515656,\n",
       " -380.2310044417493,\n",
       " -365.646608329423,\n",
       " -372.6374526074479,\n",
       " -369.7799931466118,\n",
       " -372.3156669505046,\n",
       " -370.842793216293,\n",
       " -376.8151043381481,\n",
       " -369.13071143464606,\n",
       " -374.98006314487765,\n",
       " -363.9005777950956,\n",
       " -366.3248588342087,\n",
       " -373.434394776884,\n",
       " -368.5178206100221,\n",
       " -374.36061124179395,\n",
       " -373.2293178136772,\n",
       " -370.113062559102,\n",
       " -371.6997152354819,\n",
       " -371.96844663646476,\n",
       " -375.8211075708721,\n",
       " -362.91327516764045,\n",
       " -366.5408034946996,\n",
       " -370.1215566392756,\n",
       " -373.2172569873422,\n",
       " -365.51159007387474,\n",
       " -372.2237198962621,\n",
       " -364.7354293514369,\n",
       " -369.6675963038164,\n",
       " -372.5617496811288,\n",
       " -371.6278393938543,\n",
       " -368.35411730932617,\n",
       " -368.1558288711493,\n",
       " -365.70117834642514,\n",
       " -369.64907558135303,\n",
       " -367.16005050788397,\n",
       " -359.0128441146003,\n",
       " -365.8019043315722,\n",
       " -368.57505308978915,\n",
       " -354.4240528485264,\n",
       " -368.1530990271299,\n",
       " -369.00104892336395,\n",
       " -362.7607132093504,\n",
       " -362.8239889403147,\n",
       " -366.920889363808,\n",
       " -364.6281239805961,\n",
       " -358.5355871531215,\n",
       " -366.0973464326079,\n",
       " -360.44460623334095,\n",
       " -360.8437244591677,\n",
       " -359.66928645253324,\n",
       " -360.8014684623367,\n",
       " -360.4063141869998,\n",
       " -359.50956462947136,\n",
       " -360.94617034956434,\n",
       " -369.3627878917779,\n",
       " -366.30119479083,\n",
       " -365.81077540113404,\n",
       " -357.3169522502232,\n",
       " -368.1451830129384,\n",
       " -357.7094082794166,\n",
       " -365.4416882635786,\n",
       " -366.1221773223214,\n",
       " -361.0286913310643,\n",
       " -366.9325367995254,\n",
       " -363.38051760364306,\n",
       " -356.4665277366086,\n",
       " -364.17452529339846,\n",
       " -370.1657815538515,\n",
       " -357.58823991302296,\n",
       " -366.59167217614487,\n",
       " -359.56690000964466,\n",
       " -360.60924918263476,\n",
       " -359.7719127576127,\n",
       " -366.1680112843419,\n",
       " -363.2392180678549,\n",
       " -362.661835001106,\n",
       " -362.61719920315136,\n",
       " -361.5721031778238,\n",
       " -366.63861764912156,\n",
       " -361.0072859507021,\n",
       " -358.1434960215442,\n",
       " -359.0488561400782,\n",
       " -359.059270436942,\n",
       " -361.0323157965794,\n",
       " -356.0136551067726,\n",
       " -355.9605993438319,\n",
       " -362.16223668821374,\n",
       " -351.79241028493004,\n",
       " -355.55502898852944,\n",
       " -367.10211105764955,\n",
       " -360.4278167861258,\n",
       " -360.7394737369395,\n",
       " -354.20218983340186,\n",
       " -358.58504700145744,\n",
       " -364.2155343619826,\n",
       " -356.6006513030087,\n",
       " -360.5106215560077,\n",
       " -363.9351761755053,\n",
       " -361.95245553242205,\n",
       " -359.7888071481211,\n",
       " -361.7417739093714,\n",
       " -362.7709071229419,\n",
       " -354.5989807380936,\n",
       " -363.6727291077339,\n",
       " -357.5557276598409,\n",
       " -363.17269550519933,\n",
       " -354.0777192023903,\n",
       " -364.8973253462335,\n",
       " -359.45952288835963,\n",
       " -358.3488518864792,\n",
       " -359.15594662787555,\n",
       " -362.8516230162323,\n",
       " -352.6126328651959,\n",
       " -357.6815790867466,\n",
       " -355.46850778012373,\n",
       " -352.09186723750594,\n",
       " -352.1468758365558,\n",
       " -355.60400540704507,\n",
       " -360.32464268727705,\n",
       " -361.36998826555975,\n",
       " -350.97405499472563,\n",
       " -361.3781805490353,\n",
       " -354.81244738897374,\n",
       " -359.2789001854536,\n",
       " -353.7090533556321,\n",
       " -358.94578059005937,\n",
       " -365.3428609902502,\n",
       " -357.40414143577544,\n",
       " -357.7734979381503,\n",
       " -350.4666975891951,\n",
       " -355.5093170054936,\n",
       " -351.3074316200369,\n",
       " -352.60491031841167,\n",
       " -355.6549048571724,\n",
       " -356.08194757748663,\n",
       " -349.6124254737516,\n",
       " -346.4831375621536,\n",
       " -357.4683632402756,\n",
       " -351.7676944017153,\n",
       " -361.2414900965416,\n",
       " -345.27694438924675,\n",
       " -359.84644626619144,\n",
       " -358.4343247125904,\n",
       " -352.23113779839537,\n",
       " -350.7191163083795,\n",
       " -360.27033293182416,\n",
       " -350.99923162744165,\n",
       " -359.09147248141124,\n",
       " -354.87109628749107,\n",
       " -355.6405841443325,\n",
       " -351.1424915868143,\n",
       " -356.24475258396876,\n",
       " -358.44098109834096,\n",
       " -353.89410274726015,\n",
       " -354.83306259163516,\n",
       " -355.979058343613,\n",
       " -348.87631994004585,\n",
       " -359.89668981674805,\n",
       " -355.7652787750771,\n",
       " -354.6319458797058,\n",
       " -364.82466805043185,\n",
       " -354.69142892311953,\n",
       " -352.05448474265484,\n",
       " -350.02287500069326,\n",
       " -351.46834149031804,\n",
       " -350.37488897606875,\n",
       " -347.10165696362924,\n",
       " -352.42496343981014,\n",
       " -349.1439209015887,\n",
       " -347.8768748966787,\n",
       " -357.4096693228769,\n",
       " -355.6882008562604,\n",
       " -350.9675138344028,\n",
       " -359.768841311923,\n",
       " -363.774502689431,\n",
       " -350.6697717441794,\n",
       " -348.72035261472035,\n",
       " -359.14887443740037,\n",
       " -355.63328144384525,\n",
       " -354.2173088460168,\n",
       " -353.3266632981945,\n",
       " -353.0840870836756,\n",
       " -354.23992269075796,\n",
       " -353.9957761121873,\n",
       " -353.93573813010596,\n",
       " -356.83568171342665,\n",
       " -350.67152662629445,\n",
       " -359.791113630475,\n",
       " -353.3946164149867,\n",
       " -359.76470928627384,\n",
       " -355.61417345465424,\n",
       " -361.23515480319077,\n",
       " -360.2321611616149,\n",
       " -358.24223125453517,\n",
       " -353.8116281074291,\n",
       " -352.6160749617529,\n",
       " -350.0758669191948,\n",
       " -353.21623895632234,\n",
       " -359.24137065190246,\n",
       " -355.08308165742676,\n",
       " -348.84832767949973,\n",
       " -358.4745661783099,\n",
       " -355.51483826833953,\n",
       " -363.46058887341576,\n",
       " -359.13122311376117,\n",
       " -352.532333587382,\n",
       " -345.81368541455276,\n",
       " -354.1381629720651,\n",
       " -357.7758708968441,\n",
       " -347.89174728602404,\n",
       " -356.5606568849829,\n",
       " -357.1426539163334,\n",
       " -362.28285148751974,\n",
       " -360.3294534205701,\n",
       " -349.42935169126093,\n",
       " -351.2144120529038,\n",
       " -350.94056851884307,\n",
       " -353.36536163806664,\n",
       " -356.2180358459144,\n",
       " -349.9475381822191,\n",
       " -347.6661016221366,\n",
       " -342.3830715316244,\n",
       " -359.2148571494421,\n",
       " -354.6550119792802,\n",
       " -351.8531026820709,\n",
       " -352.3969477358936,\n",
       " -355.48256569222656,\n",
       " -355.83642649835235,\n",
       " -358.6160280060959,\n",
       " -356.2521456345279,\n",
       " -359.45262790367235,\n",
       " -350.9145273045246,\n",
       " -362.62641836383284,\n",
       " -351.5911532809704,\n",
       " -359.81240717377426,\n",
       " -353.8379248670526,\n",
       " -356.69018686283897,\n",
       " -348.47953359095607,\n",
       " -358.0474603202405,\n",
       " -364.25119291834557,\n",
       " -349.69746001460675,\n",
       " -345.7783958783655,\n",
       " -353.6907718644626,\n",
       " -356.5046950045537,\n",
       " -350.59288533666415,\n",
       " -355.8582510547113,\n",
       " -353.0895735259788,\n",
       " -359.0294685886792,\n",
       " -361.1857325698432,\n",
       " -355.637110375002,\n",
       " -364.2278233760434,\n",
       " -361.5406553656314,\n",
       " -349.77966478865056,\n",
       " -362.2377005451818,\n",
       " -358.4170389447568,\n",
       " -361.7115204610153,\n",
       " -357.6926797521283,\n",
       " -352.4298877780903,\n",
       " -355.2539578344901,\n",
       " -360.92493982384127,\n",
       " -353.2086375706896,\n",
       " -358.81374655335014,\n",
       " -353.92567369912433,\n",
       " -357.9858003155297,\n",
       " -363.3045451268918,\n",
       " -360.3772719827715,\n",
       " -358.31754487247844,\n",
       " -368.7253832587618,\n",
       " -354.5089243722376,\n",
       " -362.9543904748792,\n",
       " -356.0183840608973,\n",
       " -365.44316109329,\n",
       " -358.8928515335667,\n",
       " -358.6409382552969,\n",
       " -355.40186976918403,\n",
       " -355.85520993528695,\n",
       " -356.9217465533861,\n",
       " -359.3846960588857,\n",
       " -358.53843623826947,\n",
       " -360.9760875905713,\n",
       " -352.3534544086953,\n",
       " -370.4247379952457,\n",
       " -358.94955891506305,\n",
       " -361.00475967292624,\n",
       " -363.03670097874067,\n",
       " -366.9523131351314,\n",
       " -365.6661121988094,\n",
       " -364.1613131335959,\n",
       " -359.51664168462196,\n",
       " -361.47223638865313,\n",
       " -369.381466425014,\n",
       " -356.70324948832,\n",
       " -368.8472317215643,\n",
       " -370.7343205860159,\n",
       " -368.5194955176088,\n",
       " -374.42519054203933,\n",
       " -366.82194134257963,\n",
       " -357.0390962239915,\n",
       " -361.83231173215296,\n",
       " -357.48146809420217,\n",
       " -368.4907520503451,\n",
       " -366.2850101532848,\n",
       " -370.23494635371037,\n",
       " -364.6113417805842,\n",
       " -361.1802411475438,\n",
       " -364.39132986268277,\n",
       " -361.7881961724173,\n",
       " -366.7125351760406,\n",
       " -366.66540196949734,\n",
       " -358.61045245682715,\n",
       " -365.979063602987,\n",
       " -364.6780698730703,\n",
       " -361.7488528951606,\n",
       " -368.57895367780407,\n",
       " -368.9440615441455,\n",
       " -365.12457315606633,\n",
       " -365.499214893007,\n",
       " -370.75324852283427,\n",
       " -362.54815402261704,\n",
       " -376.9309515696558,\n",
       " -359.91268921518633,\n",
       " -371.9021468372034,\n",
       " -363.59678244309504,\n",
       " -365.05137388914727,\n",
       " -367.25163610174525,\n",
       " -360.43617596381443,\n",
       " -369.35212012164504,\n",
       " -368.8274714337741,\n",
       " -367.8880278345147,\n",
       " -364.20699577846824,\n",
       " -364.8176395188591,\n",
       " -366.2180884522158,\n",
       " -364.81106797959893,\n",
       " -360.85106657157803,\n",
       " -366.0679471591248,\n",
       " -361.2481971534509,\n",
       " -356.5889248878535,\n",
       " -369.63745299126305,\n",
       " -362.547737699591,\n",
       " -362.31121311612947,\n",
       " -356.8797342671868,\n",
       " -352.87450177463614,\n",
       " -362.628451807692,\n",
       " -365.1824818836928,\n",
       " -358.99345437326866,\n",
       " -360.42114675796734,\n",
       " -369.99422322381304,\n",
       " -367.3112308006338,\n",
       " -364.23484028247015,\n",
       " -359.24944542983854,\n",
       " -375.0367354827589,\n",
       " -359.3329134056794,\n",
       " -364.27029089179365,\n",
       " -359.59058073829254,\n",
       " -367.7809484367596,\n",
       " -365.2024923596122,\n",
       " -361.07938885429314,\n",
       " -360.92940492666634,\n",
       " -366.3443967086634,\n",
       " -364.26728220363157,\n",
       " -367.8578581355674,\n",
       " -361.1846170041896,\n",
       " -364.99701596265606,\n",
       " -363.4690209577094,\n",
       " -362.9719310966028,\n",
       " -353.05502208852687,\n",
       " -361.051898340834,\n",
       " -365.3726870930166,\n",
       " -367.571195147874,\n",
       " -356.48863981247825,\n",
       " -368.6363655173615,\n",
       " -361.09520561141437,\n",
       " -357.93196723301264,\n",
       " -360.37094607142774,\n",
       " -355.28612562861105,\n",
       " -357.00568081712515,\n",
       " -370.68778486647386,\n",
       " -361.88393987977224,\n",
       " -360.4369316829422,\n",
       " -367.9754399435159,\n",
       " -368.62838960141823,\n",
       " -359.0039049291038,\n",
       " -365.4680665200737,\n",
       " -355.49004408503185,\n",
       " -369.69822274240687,\n",
       " -355.9087288729339,\n",
       " -363.86462059859275,\n",
       " -359.08649887920876,\n",
       " -356.67452602683306,\n",
       " -357.13048782635633,\n",
       " -358.72271785198825,\n",
       " -359.3610264242585,\n",
       " -358.8181322960201,\n",
       " -358.38443794273155,\n",
       " -356.66589567654785,\n",
       " -361.0618965168445,\n",
       " -355.66221816054906,\n",
       " -363.1346384326135,\n",
       " -359.98133159851517,\n",
       " -357.8822638122339,\n",
       " -359.01324161039315,\n",
       " -351.39092632570765,\n",
       " -353.2829942209577,\n",
       " -369.02450575960586,\n",
       " -362.4675793442289,\n",
       " -363.9175991943501,\n",
       " -357.52559315085745,\n",
       " -366.34209031458175,\n",
       " -359.6850584664632,\n",
       " -367.19278193004055,\n",
       " -360.6053083528942,\n",
       " -354.40275650602337,\n",
       " -353.19664157381374,\n",
       " -364.68588135584037,\n",
       " -360.6415290043808,\n",
       " -365.0448098739635,\n",
       " -359.59209363152024,\n",
       " -358.27496445359634,\n",
       " -364.22809254255344,\n",
       " -358.1411437038442,\n",
       " -367.09741697267157,\n",
       " -352.2713324516239,\n",
       " -369.375596984208,\n",
       " -359.4605877790893,\n",
       " -376.2940254644928,\n",
       " -371.4473365819019,\n",
       " -360.6458799572588,\n",
       " -366.20181362221757,\n",
       " -371.50463979564586,\n",
       " -365.0940234594002,\n",
       " -360.40319455522894,\n",
       " -360.69808659294756,\n",
       " -359.7063685170515,\n",
       " -372.620758441576,\n",
       " -371.6793654518428,\n",
       " -360.3067455738864,\n",
       " -356.6870608056247,\n",
       " -363.4506623774606,\n",
       " -362.6953277240098,\n",
       " -363.7453696690617,\n",
       " -358.35160842707023,\n",
       " -366.64175697758213,\n",
       " -370.25689902988114,\n",
       " -365.5096744236869,\n",
       " -361.08905813738846,\n",
       " -362.0653291330831,\n",
       " -369.22419446559843,\n",
       " -364.92719855487485,\n",
       " -362.3957651019028,\n",
       " -353.72947996136907,\n",
       " -366.2458450866416,\n",
       " -365.79382877207354,\n",
       " -363.47876545552026,\n",
       " -364.461372997937,\n",
       " -362.3690986706122,\n",
       " -360.8447153601526,\n",
       " -350.05168925440324,\n",
       " -360.3959485813728,\n",
       " -352.04669299832517,\n",
       " -358.9294916358964,\n",
       " -354.11544597029445,\n",
       " -350.9302224462846,\n",
       " -357.17512691532755,\n",
       " -365.2669889391825,\n",
       " -363.03752779378544,\n",
       " -364.1556658852443,\n",
       " -347.4259400277521,\n",
       " -354.4493863479019,\n",
       " -356.3417508517589,\n",
       " -355.4900224403839,\n",
       " -362.22852951796233,\n",
       " -350.8755370581242,\n",
       " -356.9980922691728,\n",
       " -360.3486327824186,\n",
       " -350.30964035256255,\n",
       " -354.58137016600233,\n",
       " -348.54196091983897,\n",
       " -356.4558945121138,\n",
       " -356.1080442980796,\n",
       " -348.4045055235253,\n",
       " -343.8271538262368,\n",
       " -355.6112740244941,\n",
       " -349.386783335311,\n",
       " -345.900211332998,\n",
       " -355.5419922390257,\n",
       " -353.48736966986,\n",
       " -341.04776196686174,\n",
       " -347.5413038180899,\n",
       " -351.5792982993204,\n",
       " -343.08256294645975,\n",
       " -348.1439419523899,\n",
       " -345.94959806753445,\n",
       " -355.51444559541864,\n",
       " -349.9972003990991,\n",
       " -344.76746970015904,\n",
       " -343.7939664986653,\n",
       " -341.3060086014491,\n",
       " -335.4947149910119,\n",
       " -351.33336830583715,\n",
       " -340.6167373817832,\n",
       " -355.359025612553,\n",
       " -343.9409433005004,\n",
       " -341.15385630001254,\n",
       " -348.5774588892403,\n",
       " -343.4723662814882,\n",
       " -356.0339433415419,\n",
       " -347.0503397895851,\n",
       " -340.5001522048238,\n",
       " -346.10991260875437,\n",
       " -345.8680517996421,\n",
       " -342.1504608709288,\n",
       " -346.64978637861657,\n",
       " -350.7447417725936,\n",
       " -338.2400861767042,\n",
       " -349.1600507598136,\n",
       " -349.9690029417337,\n",
       " -339.36275164559856,\n",
       " -340.5816823738759,\n",
       " -345.72499608776707,\n",
       " -350.0599776799576,\n",
       " -338.78848268924514,\n",
       " -342.85528066651455,\n",
       " -342.85568326966137,\n",
       " -340.61060460513494,\n",
       " -342.32240160247153,\n",
       " -339.0366958218552,\n",
       " -345.8106491395836,\n",
       " -349.15114302603075,\n",
       " -347.9992465400533,\n",
       " -342.4230473592903,\n",
       " -331.6493316373934,\n",
       " -336.2587250875363,\n",
       " -342.12969107140475,\n",
       " -340.73184982859175,\n",
       " -341.7560157351977,\n",
       " -356.1646324217209,\n",
       " -346.6944637247074,\n",
       " -346.17487275678343,\n",
       " -343.8061022759957,\n",
       " -338.42806652535955,\n",
       " -343.2256681793957,\n",
       " -339.5727695418416,\n",
       " -344.87721674299416,\n",
       " -342.92472694358315,\n",
       " -343.9208552516045,\n",
       " -342.26520750148353,\n",
       " -349.2548258032129,\n",
       " -338.3335852485214,\n",
       " -337.17211039575824,\n",
       " -338.6692985749136,\n",
       " -328.9089762431855,\n",
       " -332.21749446892096,\n",
       " -341.1584760941177,\n",
       " -339.7086475830606,\n",
       " -350.4622785015323,\n",
       " -346.40693832113345,\n",
       " -341.31133458077034,\n",
       " -342.0668061113924,\n",
       " -336.5473312003003,\n",
       " -335.37322869635403,\n",
       " -335.8452995205141,\n",
       " -335.5407762064654,\n",
       " -350.07482783825276,\n",
       " -332.6651152153748,\n",
       " -332.4024985207723,\n",
       " -335.2597154843526,\n",
       " -336.82362467087654,\n",
       " -334.69483712337376,\n",
       " -341.4781974211991,\n",
       " -330.7615777126689,\n",
       " -321.17200350429204,\n",
       " -335.82054650689304,\n",
       " -338.03998298908374,\n",
       " -339.0477334433814,\n",
       " -340.1826644112167,\n",
       " -343.9050068707533,\n",
       " -333.94190150701513,\n",
       " -336.0691562862864,\n",
       " -335.64832406329197,\n",
       " -333.97135344588116,\n",
       " -355.9280588274029,\n",
       " -334.6275640683786,\n",
       " -336.6799222455675,\n",
       " -335.5124675165632,\n",
       " -343.03699382960383,\n",
       " -351.45867116758734,\n",
       " -340.54943295452165,\n",
       " -351.55181668917925,\n",
       " -336.47949693684046,\n",
       " -346.29004641383716,\n",
       " -346.75346807439627,\n",
       " -341.6355518972168,\n",
       " -350.27176090015803,\n",
       " -339.4898184266682,\n",
       " -339.576319813714,\n",
       " -340.81979315979913,\n",
       " -350.11341341887385,\n",
       " -344.4675184583542,\n",
       " -340.66135937742945,\n",
       " -339.3541646881364,\n",
       " -345.0105437158936,\n",
       " -338.94640414546865,\n",
       " -348.1608518298755,\n",
       " -341.79802566140614,\n",
       " -340.80007205763303,\n",
       " -329.5075149034372,\n",
       " -343.0785977266586,\n",
       " -333.09635155607754,\n",
       " -338.67482426581677,\n",
       " -350.02605025762693,\n",
       " -332.4825625458451,\n",
       " -332.7784465081315,\n",
       " -349.35663566393134,\n",
       " -330.0396921438631,\n",
       " -341.4930115883795,\n",
       " -319.9128183411089,\n",
       " -334.2546171533272,\n",
       " -331.9370903658859,\n",
       " -335.01103222431715,\n",
       " -337.52785061496473,\n",
       " -327.74871287117423,\n",
       " -335.6893423205953,\n",
       " -334.279205294165,\n",
       " -330.21384467330785,\n",
       " -334.17615522883403,\n",
       " -334.23281713344267,\n",
       " -333.8043167182976,\n",
       " -327.8198501710215,\n",
       " -333.03930654708887,\n",
       " -320.7325647380296,\n",
       " -332.07844041251434,\n",
       " -329.1856405569778,\n",
       " -332.1471106731913,\n",
       " -331.7736114460091,\n",
       " -337.5272011809038,\n",
       " -335.909677307804,\n",
       " -332.14329039811076,\n",
       " -331.55552267810106,\n",
       " -337.99478424274565,\n",
       " -331.1745405262398,\n",
       " -337.4421024854108,\n",
       " -332.33372910794986,\n",
       " -333.6050853439368,\n",
       " -324.1086467154631,\n",
       " -325.96500373411277,\n",
       " -328.8687143671374,\n",
       " -330.46962860276983,\n",
       " -324.5691151834164,\n",
       " -338.50766297247367,\n",
       " -330.74380406793387,\n",
       " -339.0124482361231,\n",
       " -336.1911948429729,\n",
       " -336.5657501216512,\n",
       " -339.2347356138174,\n",
       " -332.62814989323226,\n",
       " -333.643712308295,\n",
       " -346.96474104434594,\n",
       " -348.9868924033252,\n",
       " -340.0780026829576,\n",
       " -335.8852905949352,\n",
       " -351.2326034206618,\n",
       " -341.3088123576492,\n",
       " -344.55207491149224,\n",
       " -343.680496757952,\n",
       " -331.77262884613947,\n",
       " -337.866854286156,\n",
       " -331.8307453025594,\n",
       " -335.5319101652541,\n",
       " -335.8047637070539,\n",
       " -341.2670851547547,\n",
       " -332.02808185375807,\n",
       " -333.3315251557556,\n",
       " -319.88958380716133,\n",
       " -334.60569531010617,\n",
       " -330.70673779368195,\n",
       " -331.2804807804552,\n",
       " -332.5618841353303,\n",
       " -340.98342214737085,\n",
       " -333.0941659886522,\n",
       " -334.35709394585757,\n",
       " -330.61553729593646,\n",
       " -330.08120346446196,\n",
       " -346.7648919855461,\n",
       " -327.95738654101973,\n",
       " -326.33969928207864,\n",
       " -341.99801804697506,\n",
       " -335.6265225956357,\n",
       " -336.72581428798827,\n",
       " -329.6924327940811,\n",
       " -326.7857598002012,\n",
       " -331.33520086228,\n",
       " -331.76928330158506,\n",
       " -332.66733565615596,\n",
       " -330.79134251274735,\n",
       " -333.67097227077454,\n",
       " -337.6255891025211,\n",
       " -332.61287082439037,\n",
       " -330.78803046962673,\n",
       " -329.85029254601346,\n",
       " -339.0231113584706,\n",
       " -330.9973826691566,\n",
       " -327.728434057661,\n",
       " -337.45030282198024,\n",
       " -339.1271188181328,\n",
       " -338.9081490431336,\n",
       " -342.83965716233104,\n",
       " -330.54322279399304,\n",
       " -340.59776915548,\n",
       " -332.1961555507871,\n",
       " -328.0880550945748,\n",
       " -329.49154926468685,\n",
       " -332.385669161501,\n",
       " -337.9911653544141,\n",
       " -337.8860237346173,\n",
       " -335.6866638508685,\n",
       " -329.979267134981,\n",
       " -330.03801423435266,\n",
       " -331.26506227093904,\n",
       " -338.2032276989193,\n",
       " -337.7462959791108,\n",
       " -337.65960442833,\n",
       " -332.9699437173168,\n",
       " -338.4153653840215,\n",
       " -344.0935282576668,\n",
       " -334.84948724851654,\n",
       " -332.1141579895908,\n",
       " -343.41823027212695,\n",
       " -334.99232428417224,\n",
       " -346.28409971281775,\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_agent.training(envs, tmax, tmax, episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38254a4-3c1d-43e8-bec3-a3bdc51e0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_agent.training(envs, tmax, tmax, episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de731b96-5445-427d-9572-63587aca0500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(envs.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdbeb67-a65e-491e-b681-fca455171e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "envs.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642d92d-a362-4018-ad83-805859cb77b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "t = 0\n",
    "_ = envs.reset()\n",
    "fig, ax = plt.subplots(1,3, figsize = (30,10))\n",
    "while t < 1000:\n",
    "    actions = np.array([1, 0, 1])\n",
    "    observations, rewards, termination, truncation, infos = envs.step(envs.action_space.sample())\n",
    "    t += 1\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    for i in range(3):\n",
    "        ax[i].imshow(envs.render())\n",
    "    plt.show()\n",
    "    \n",
    "    if np.any(termination):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede1024-8739-4429-ac32-d2449020b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = envs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762890ee-9a84-4228-ada6-c48427cb47a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b177b6d-8086-4c52-9608-658089ad59d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ea705-1d6f-4622-adb7-f51591d52f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(gym.vector.make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3b7bde-ca57-4e8a-bfd1-a6de0609074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.action_space.sample().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a3e6c-cf81-4964-adbd-8b7b55154b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t = 0\n",
    "while t < 1000:\n",
    "    actions = np.array([1, 0, 1])\n",
    "    observations, rewards, termination, truncation, infos = envs.step(envs.action_space.sample())\n",
    "    t += 1\n",
    "    print(rewards.mean())\n",
    "    if np.any(termination):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da2391-1177-487e-9ca9-baf1ab300cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_new",
   "language": "python",
   "name": "pytorch_gpu_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
