{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc786f33-8f00-4d5c-bd9f-2581eaef44e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from reacher_environment import ReacherEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d976d11-f392-4f75-95d4-33dd32a99dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Number of actions: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n"
     ]
    }
   ],
   "source": [
    "convert_fn = lambda x: x\n",
    "env = ReacherEnvironment('./p2_continuous-control/multiagent/Reacher.app', convert_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6a276-6748-4ce6-a2c5-7e572a2914df",
   "metadata": {},
   "source": [
    "### Defining Policy-Value Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444f520d-122d-4f01-b662-c5b1986a42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import beta\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class Policy_Network(nn.Module):\n",
    "    def __init__(self, input_size, action_size):\n",
    "        super(Policy_Network, self).__init__()\n",
    "        # outputs beta likelyhood parameters\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 2*action_size)\n",
    "        self.fcalpha = nn.Linear(2*action_size, action_size)\n",
    "        self.fcbeta = nn.Linear(2*action_size, action_size)\n",
    "        self.softplus_act = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        a = self.softplus_act(self.fcalpha(x)) + 1.\n",
    "        b = self.softplus_act(self.fcbeta(x)) + 1.\n",
    "        beta_dist = beta.Beta(a,b)\n",
    "        return beta_dist, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee87d8f-1907-4870-8069-497352dfc1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from reinforce import REINFORCE\n",
    "import torch.optim as optim\n",
    "episode = 3000\n",
    "tmax = 1000\n",
    "learning_rate = 1e-3\n",
    "state_dim = 33\n",
    "action_dim = 4\n",
    "\n",
    "# Initializing policy network, optimizer and agent\n",
    "policy_network = Policy_Network(state_dim,action_dim).to(device)\n",
    "optimizer = optim.Adam(policy_network.parameters(), lr=learning_rate)\n",
    "reinforce_agent = REINFORCE(policy_network,\n",
    "                 optimizer, \n",
    "                 entropy_reg_schedule = lambda old_value, rewards: 0.995*old_value,\n",
    "                 entropy_reg_start=0.01,\n",
    "                 gamma_schedule = lambda old_value, rewards: 1. - 0.998*(1. - old_value),\n",
    "                 gamma_start = 0.96,\n",
    "                 target_score=30,\n",
    "                 target_score_window=100,\n",
    "                 action_transform = lambda x: -1+2*x,\n",
    "                 loss_type = \"ratio\",\n",
    "                 verbosity = 50)\n",
    "reinforce_agent.training(env, tmax, tmax, episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ee476e-d5b8-4f03-888a-17c530002ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4054999909363687 0.15993600000000002 <function <lambda>.<locals>.<lambda> at 0x7fee69843d90> 0.009998\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to function.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d2c115e25335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                  \u001b[0maction_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                  verbosity = 100)\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mppo_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/RL/Udacity_assignment/ContinousControlReacher/ppo.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, env, tmax, tmax_for_training, n_episodes)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_of_last_x_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;31m# display some progress every iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\r Episode : {e+1}\\t Average reward in last 100 episode : {avg_of_last_x_episodes:.2f} epsilon_policy : {epsilon:.3f} gamma : {gamma:.3f} entropy_reg : {entropy_reg:.3f}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbosity\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\r Episode : {e+1}\\t Average reward in last 100 episode : {avg_of_last_x_episodes:.2f} epsilon_policy : {epsilon:.3f} gamma : {gamma:.3f} entropy_reg : {entropy_reg:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to function.__format__"
     ]
    }
   ],
   "source": [
    "from ppo import PPO\n",
    "import torch.optim as optim\n",
    "learning_rate = 1e-3\n",
    "episode = 5000\n",
    "tmax = 1000\n",
    "state_dim = 33\n",
    "action_dim = 4\n",
    "\n",
    "# Initializing policy network, optimizer and agent\n",
    "policy_network = Policy_Network(state_dim,action_dim).to(device)\n",
    "optimizer = optim.Adam(policy_network.parameters(), lr=learning_rate)\n",
    "ppo_agent = PPO(policy_network,\n",
    "                 optimizer,\n",
    "                 SGD_steps=4,\n",
    "                 ppo_policy_epsilon_schedule=lambda old_value, rewards: 0.9996*old_value,\n",
    "                 ppo_policy_epsilon_start=0.16,\n",
    "                 entropy_reg_schedule = lambda old_value, rewards: 0.9998*old_value,\n",
    "                 entropy_reg_start=0.01,\n",
    "                 gamma_schedule = lambda old_value, rewards: 1.- 0.9998*(1. - old_value),\n",
    "                 gamma_start = 0.98,\n",
    "                 target_score=30,\n",
    "                 target_score_window=100,\n",
    "                 action_transform = lambda x: -1+2*x,\n",
    "                 verbosity = 100)\n",
    "ppo_agent.training(env, tmax, tmax, episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cae9c6-afe8-4f54-aa2f-7a11c8c2f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import beta\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class Policy_Value_Network(nn.Module):\n",
    "    def __init__(self, input_size, action_size):\n",
    "        super(Policy_Value_Network, self).__init__()\n",
    "        # outputs beta likelyhood parameters\n",
    "        self.policy_network = Policy_Network(input_size, action_size)\n",
    "        self.fcval = nn.Linear(2*action_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        beta_dist,x = self.policy_network(x)\n",
    "        values = self.fcval(x)\n",
    "        return beta_dist, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ed0d08-f058-4bf9-adb1-109f8fb2bc3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 100\t Average reward in last 100 episode : 0.90 epsilon_policy : 0.144 epsilon_value : 0.480 lambda_gae : 0.792 gamma : 0.985 entropy_reg : 0.010\n",
      " Episode : 200\t Average reward in last 100 episode : 3.12 epsilon_policy : 0.138 epsilon_value : 0.462 lambda_gae : 0.784 gamma : 0.985 entropy_reg : 0.010\n",
      " Episode : 300\t Average reward in last 100 episode : 4.75 epsilon_policy : 0.133 epsilon_value : 0.443 lambda_gae : 0.776 gamma : 0.985 entropy_reg : 0.010\n",
      " Episode : 400\t Average reward in last 100 episode : 6.00 epsilon_policy : 0.128 epsilon_value : 0.426 lambda_gae : 0.769 gamma : 0.986 entropy_reg : 0.010\n",
      " Episode : 500\t Average reward in last 100 episode : 8.31 epsilon_policy : 0.123 epsilon_value : 0.409 lambda_gae : 0.761 gamma : 0.986 entropy_reg : 0.010\n",
      " Episode : 600\t Average reward in last 100 episode : 10.45 epsilon_policy : 0.118 epsilon_value : 0.393 lambda_gae : 0.753 gamma : 0.986 entropy_reg : 0.009\n",
      " Episode : 700\t Average reward in last 100 episode : 11.89 epsilon_policy : 0.113 epsilon_value : 0.378 lambda_gae : 0.746 gamma : 0.986 entropy_reg : 0.009\n",
      " Episode : 800\t Average reward in last 100 episode : 14.33 epsilon_policy : 0.109 epsilon_value : 0.363 lambda_gae : 0.738 gamma : 0.986 entropy_reg : 0.009\n",
      " Episode : 900\t Average reward in last 100 episode : 15.22 epsilon_policy : 0.105 epsilon_value : 0.349 lambda_gae : 0.731 gamma : 0.986 entropy_reg : 0.009\n",
      " Episode : 1000\t Average reward in last 100 episode : 17.00 epsilon_policy : 0.101 epsilon_value : 0.335 lambda_gae : 0.724 gamma : 0.986 entropy_reg : 0.009\n",
      " Episode : 1100\t Average reward in last 100 episode : 17.21 epsilon_policy : 0.097 epsilon_value : 0.322 lambda_gae : 0.717 gamma : 0.987 entropy_reg : 0.009\n",
      " Episode : 1200\t Average reward in last 100 episode : 17.60 epsilon_policy : 0.093 epsilon_value : 0.309 lambda_gae : 0.710 gamma : 0.987 entropy_reg : 0.009\n",
      " Episode : 1300\t Average reward in last 100 episode : 18.21 epsilon_policy : 0.089 epsilon_value : 0.297 lambda_gae : 0.702 gamma : 0.987 entropy_reg : 0.009\n",
      " Episode : 1400\t Average reward in last 100 episode : 17.73 epsilon_policy : 0.086 epsilon_value : 0.286 lambda_gae : 0.695 gamma : 0.987 entropy_reg : 0.009\n",
      " Episode : 1500\t Average reward in last 100 episode : 18.30 epsilon_policy : 0.082 epsilon_value : 0.274 lambda_gae : 0.689 gamma : 0.987 entropy_reg : 0.009\n",
      " Episode : 1600\t Average reward in last 100 episode : 18.45 epsilon_policy : 0.079 epsilon_value : 0.264 lambda_gae : 0.682 gamma : 0.987 entropy_reg : 0.009\n",
      " Episode : 1700\t Average reward in last 100 episode : 19.02 epsilon_policy : 0.076 epsilon_value : 0.253 lambda_gae : 0.675 gamma : 0.987 entropy_reg : 0.008\n",
      " Episode : 1800\t Average reward in last 100 episode : 20.94 epsilon_policy : 0.073 epsilon_value : 0.243 lambda_gae : 0.668 gamma : 0.987 entropy_reg : 0.008\n",
      " Episode : 1900\t Average reward in last 100 episode : 23.11 epsilon_policy : 0.070 epsilon_value : 0.234 lambda_gae : 0.662 gamma : 0.988 entropy_reg : 0.008\n",
      " Episode : 2000\t Average reward in last 100 episode : 25.75 epsilon_policy : 0.067 epsilon_value : 0.225 lambda_gae : 0.655 gamma : 0.988 entropy_reg : 0.008\n",
      " Episode : 2100\t Average reward in last 100 episode : 29.29 epsilon_policy : 0.065 epsilon_value : 0.216 lambda_gae : 0.648 gamma : 0.988 entropy_reg : 0.008\n",
      " Episode : 2121\t Average reward in last 100 episode : 30.04 epsilon_policy : 0.064 epsilon_value : 0.214 lambda_gae : 0.647 gamma : 0.988 entropy_reg : 0.008Environment solved in episodes = 2121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17049999618902803,\n",
       " 0.23499999474734068,\n",
       " 0.2269999949261546,\n",
       " 0.18099999595433475,\n",
       " 0.1719999961555004,\n",
       " 0.10449999766424298,\n",
       " 0.14799999669194222,\n",
       " 0.2079999953508377,\n",
       " 0.15349999656900765,\n",
       " 0.13099999707192184,\n",
       " 0.2404999946244061,\n",
       " 0.2249999949708581,\n",
       " 0.26049999417737124,\n",
       " 0.3069999931380153,\n",
       " 0.22949999487027525,\n",
       " 0.4274999904446304,\n",
       " 0.41849999064579607,\n",
       " 0.3439999923110008,\n",
       " 0.48799998909235,\n",
       " 0.37499999161809683,\n",
       " 0.6789999848231674,\n",
       " 0.4779999893158674,\n",
       " 0.4399999901652336,\n",
       " 0.5199999883770943,\n",
       " 0.5094999886117876,\n",
       " 0.5124999885447323,\n",
       " 0.6459999855607748,\n",
       " 0.4604999897070229,\n",
       " 0.5684999872930347,\n",
       " 0.5899999868124723,\n",
       " 0.6644999851472676,\n",
       " 0.5954999866895377,\n",
       " 0.6664999851025641,\n",
       " 0.7574999830685556,\n",
       " 0.6034999865107238,\n",
       " 0.7619999829679728,\n",
       " 0.6694999850355089,\n",
       " 0.6724999849684536,\n",
       " 0.8354999813251197,\n",
       " 0.9324999791570008,\n",
       " 0.8179999817162752,\n",
       " 0.580999987013638,\n",
       " 0.7599999830126762,\n",
       " 0.9464999788440764,\n",
       " 1.1764999737031758,\n",
       " 0.9384999790228903,\n",
       " 0.6034999865107238,\n",
       " 1.003499977570027,\n",
       " 0.9904999778605997,\n",
       " 0.9329999791458249,\n",
       " 1.172999973781407,\n",
       " 0.886499980185181,\n",
       " 0.9359999790787696,\n",
       " 0.7679999828338623,\n",
       " 1.1999999731779099,\n",
       " 0.8139999818056822,\n",
       " 0.8949999799951911,\n",
       " 0.9839999780058861,\n",
       " 1.045999976620078,\n",
       " 1.0159999772906303,\n",
       " 1.1569999741390347,\n",
       " 1.006499977502972,\n",
       " 1.2214999726973474,\n",
       " 1.1179999750107528,\n",
       " 1.0464999766089023,\n",
       " 1.3904999689199031,\n",
       " 0.9664999783970416,\n",
       " 1.1979999732226134,\n",
       " 1.1154999750666321,\n",
       " 1.1299999747425318,\n",
       " 1.0519999764859675,\n",
       " 1.1064999752677978,\n",
       " 1.0354999768547715,\n",
       " 1.2694999716244637,\n",
       " 1.1344999746419488,\n",
       " 1.3144999706186353,\n",
       " 1.0969999754801392,\n",
       " 1.370499969366938,\n",
       " 1.552999965287745,\n",
       " 1.5834999646060168,\n",
       " 1.309499970730394,\n",
       " 1.4259999681264162,\n",
       " 1.3734999692998826,\n",
       " 1.2914999711327255,\n",
       " 1.2184999727644026,\n",
       " 1.30049997093156,\n",
       " 1.292999971099198,\n",
       " 1.3274999703280628,\n",
       " 1.5169999660924076,\n",
       " 1.552999965287745,\n",
       " 1.4179999683052302,\n",
       " 1.278499971423298,\n",
       " 1.398499968741089,\n",
       " 1.6874999622814357,\n",
       " 1.4449999677017331,\n",
       " 1.6544999630190431,\n",
       " 1.8129999594762922,\n",
       " 1.7499999608844519,\n",
       " 2.090499953273684,\n",
       " 2.122499952558428,\n",
       " 1.850499958638102,\n",
       " 1.7829999601468445,\n",
       " 1.993999955430627,\n",
       " 1.7524999608285725,\n",
       " 1.6249999636784196,\n",
       " 1.9404999566264451,\n",
       " 1.6564999629743398,\n",
       " 1.784999960102141,\n",
       " 1.8769999580457806,\n",
       " 1.707499961834401,\n",
       " 1.967499956022948,\n",
       " 2.126999952457845,\n",
       " 2.0659999538213016,\n",
       " 1.8129999594762922,\n",
       " 2.3189999481663106,\n",
       " 1.8309999590739607,\n",
       " 1.9434999565593898,\n",
       " 2.226999950222671,\n",
       " 1.9664999560452998,\n",
       " 2.4524999451823533,\n",
       " 1.9519999563694,\n",
       " 2.16149995168671,\n",
       " 2.322999948076904,\n",
       " 2.1094999528490006,\n",
       " 2.1594999517314135,\n",
       " 2.0884999533183874,\n",
       " 2.8629999360069633,\n",
       " 2.7479999385774136,\n",
       " 2.64949994077906,\n",
       " 2.911999934911728,\n",
       " 2.9949999330565333,\n",
       " 2.4209999458864333,\n",
       " 2.2979999486356975,\n",
       " 2.563999942690134,\n",
       " 3.1464999296702443,\n",
       " 2.575499942433089,\n",
       " 2.521499943640083,\n",
       " 2.88799993544817,\n",
       " 3.29249992640689,\n",
       " 3.4374999231658876,\n",
       " 2.710999939404428,\n",
       " 2.8449999364092946,\n",
       " 3.0269999323412775,\n",
       " 2.7294999389909207,\n",
       " 3.238999927602708,\n",
       " 3.3244999256916343,\n",
       " 2.9539999339729546,\n",
       " 2.8214999369345604,\n",
       " 3.4069999238476156,\n",
       " 3.427499923389405,\n",
       " 3.449999922886491,\n",
       " 3.2989999262616037,\n",
       " 3.5849999198690057,\n",
       " 3.3329999255016447,\n",
       " 3.148499929625541,\n",
       " 3.5099999215453863,\n",
       " 3.26099992711097,\n",
       " 3.8094999148510396,\n",
       " 3.6849999176338315,\n",
       " 3.881499913241714,\n",
       " 3.5839999198913572,\n",
       " 2.8634999359957876,\n",
       " 3.5664999202825127,\n",
       " 3.4909999219700696,\n",
       " 3.2154999281279744,\n",
       " 2.8799999356269836,\n",
       " 2.916499934811145,\n",
       " 3.8639999136328695,\n",
       " 3.7244999167509376,\n",
       " 4.300999903865159,\n",
       " 3.647499918472022,\n",
       " 3.881499913241714,\n",
       " 3.755499916058034,\n",
       " 3.7149999169632792,\n",
       " 3.5879999198019505,\n",
       " 4.324999903328717,\n",
       " 4.054999909363687,\n",
       " 4.05299990940839,\n",
       " 4.2589999048039315,\n",
       " 3.7869999153539537,\n",
       " 4.203999906033277,\n",
       " 4.407999901473522,\n",
       " 3.454999922774732,\n",
       " 4.281499904301017,\n",
       " 4.220999905653298,\n",
       " 4.1019999083131555,\n",
       " 4.0614999092184005,\n",
       " 3.6769999178126453,\n",
       " 3.8084999148733916,\n",
       " 4.221499905642122,\n",
       " 4.261999904736877,\n",
       " 3.8099999148398638,\n",
       " 4.163999906927347,\n",
       " 4.133999907597899,\n",
       " 4.272499904502183,\n",
       " 4.048999909497797,\n",
       " 4.418999901227653,\n",
       " 4.271499904524535,\n",
       " 3.9834999109618368,\n",
       " 4.135999907553196,\n",
       " 3.9134999125264587,\n",
       " 3.9489999117329715,\n",
       " 4.521999898925424,\n",
       " 4.58449989752844,\n",
       " 3.846499914024025,\n",
       " 4.399499901663512,\n",
       " 4.1049999082461,\n",
       " 4.6934998950921,\n",
       " 4.531499898713082,\n",
       " 4.96349988905713,\n",
       " 3.8384999142028393,\n",
       " 4.0484999095089735,\n",
       " 4.201499906089157,\n",
       " 4.356999902613461,\n",
       " 4.40049990164116,\n",
       " 3.8229999145492912,\n",
       " 3.8594999137334525,\n",
       " 4.837999891862273,\n",
       " 4.007499910425395,\n",
       " 4.920999890007079,\n",
       " 3.9584999115206303,\n",
       " 4.502499899361283,\n",
       " 4.956999889202416,\n",
       " 4.129999907687306,\n",
       " 4.2129999058321115,\n",
       " 4.37499990221113,\n",
       " 4.2459999050945045,\n",
       " 4.60999989695847,\n",
       " 4.42099990118295,\n",
       " 4.14499990735203,\n",
       " 4.258499904815108,\n",
       " 4.852499891538173,\n",
       " 5.799499870371074,\n",
       " 4.231999905407429,\n",
       " 4.710999894700945,\n",
       " 4.735499894153326,\n",
       " 4.655499895941466,\n",
       " 4.521999898925424,\n",
       " 4.420499901194125,\n",
       " 4.154999907128513,\n",
       " 4.720999894477427,\n",
       " 4.553499898221344,\n",
       " 4.309999903663993,\n",
       " 5.151999884843827,\n",
       " 4.675499895494431,\n",
       " 4.530999898724258,\n",
       " 4.835999891906977,\n",
       " 5.331999880820513,\n",
       " 4.45499990042299,\n",
       " 4.610499896947294,\n",
       " 5.014499887917191,\n",
       " 5.0784998864866795,\n",
       " 5.180999884195626,\n",
       " 4.719499894510955,\n",
       " 4.445999900624156,\n",
       " 4.49849989945069,\n",
       " 4.708499894756824,\n",
       " 4.956999889202416,\n",
       " 4.87399989105761,\n",
       " 5.0379998873919245,\n",
       " 4.806499892566353,\n",
       " 4.431999900937081,\n",
       " 4.897999890521168,\n",
       " 5.297499881591648,\n",
       " 4.896999890543521,\n",
       " 5.033999887481332,\n",
       " 5.466999877803028,\n",
       " 4.801499892678112,\n",
       " 4.671499895583838,\n",
       " 4.946999889425934,\n",
       " 4.481499899830669,\n",
       " 5.421499878820032,\n",
       " 4.740999894030392,\n",
       " 4.681499895360321,\n",
       " 4.924999889917672,\n",
       " 5.3554998802952465,\n",
       " 4.689999895170331,\n",
       " 5.070999886654318,\n",
       " 4.964999889023602,\n",
       " 4.831499892007559,\n",
       " 5.256999882496894,\n",
       " 5.505499876942485,\n",
       " 5.03499988745898,\n",
       " 5.323499881010503,\n",
       " 4.944999889470637,\n",
       " 5.340999880619347,\n",
       " 5.48549987738952,\n",
       " 4.975999888777733,\n",
       " 5.407499879132956,\n",
       " 5.083499886374921,\n",
       " 5.287999881803989,\n",
       " 5.297499881591648,\n",
       " 5.216999883390963,\n",
       " 4.97199988886714,\n",
       " 5.370999879948795,\n",
       " 5.673999873176217,\n",
       " 5.0544998870231215,\n",
       " 5.298499881569296,\n",
       " 5.604999874718487,\n",
       " 5.374499879870564,\n",
       " 5.586999875120819,\n",
       " 5.460499877948314,\n",
       " 4.740999894030392,\n",
       " 5.069499886687845,\n",
       " 5.036499887425452,\n",
       " 5.374499879870564,\n",
       " 5.165999884530902,\n",
       " 5.477499877568334,\n",
       " 5.538999876193702,\n",
       " 5.958499866817147,\n",
       " 5.352999880351126,\n",
       " 5.846999869309366,\n",
       " 5.5289998764172195,\n",
       " 5.642499873880297,\n",
       " 5.948999867029488,\n",
       " 5.643499873857945,\n",
       " 5.297499881591648,\n",
       " 5.643999873846769,\n",
       " 5.796999870426953,\n",
       " 5.930499867442995,\n",
       " 5.31949988109991,\n",
       " 6.2869998594746,\n",
       " 5.394999879412353,\n",
       " 5.460499877948314,\n",
       " 5.232499883044511,\n",
       " 5.486999877355993,\n",
       " 6.068999864347279,\n",
       " 5.691499872785061,\n",
       " 6.29799985922873,\n",
       " 5.624499874282629,\n",
       " 6.23499986063689,\n",
       " 5.6839998729526995,\n",
       " 6.36699985768646,\n",
       " 6.431999856233597,\n",
       " 5.690999872796238,\n",
       " 6.490999854914844,\n",
       " 5.747999871522188,\n",
       " 5.915499867778271,\n",
       " 5.846999869309366,\n",
       " 5.938999867253005,\n",
       " 5.722999872080981,\n",
       " 5.8369998695328835,\n",
       " 5.592499874997884,\n",
       " 5.915999867767096,\n",
       " 5.852999869175255,\n",
       " 5.5509998759254815,\n",
       " 5.354499880317599,\n",
       " 5.6709998732432725,\n",
       " 5.23599988296628,\n",
       " 5.533499876316637,\n",
       " 6.213999861106276,\n",
       " 5.856999869085849,\n",
       " 6.212999861128628,\n",
       " 5.66099987346679,\n",
       " 6.2654998599551615,\n",
       " 5.772999870963394,\n",
       " 6.057999864593148,\n",
       " 5.935999867320061,\n",
       " 6.314999858848751,\n",
       " 6.2579998601227995,\n",
       " 6.397999856993556,\n",
       " 6.096499863732606,\n",
       " 6.5274998540990055,\n",
       " 6.594999852590263,\n",
       " 6.362499857787043,\n",
       " 5.9699998665601015,\n",
       " 5.788499870616943,\n",
       " 5.714499872270972,\n",
       " 5.854499869141728,\n",
       " 6.453999855741858,\n",
       " 6.565499853249639,\n",
       " 5.9219998676329855,\n",
       " 5.5969998748973016,\n",
       " 6.107499863486737,\n",
       " 6.709999850019813,\n",
       " 6.529999854043126,\n",
       " 6.4959998548030855,\n",
       " 6.110499863419681,\n",
       " 6.293999859318137,\n",
       " 6.3429998582229015,\n",
       " 6.606999852322042,\n",
       " 6.667499850969762,\n",
       " 6.78349984837696,\n",
       " 6.766999848745764,\n",
       " 6.045499864872545,\n",
       " 6.744999849237502,\n",
       " 6.115499863307923,\n",
       " 6.299499859195203,\n",
       " 6.461999855563045,\n",
       " 6.328999858535826,\n",
       " 6.691999850422144,\n",
       " 6.721999849751592,\n",
       " 5.968999866582453,\n",
       " 6.641999851539731,\n",
       " 6.601999852433801,\n",
       " 6.648999851383269,\n",
       " 7.237499838229269,\n",
       " 6.496499854791909,\n",
       " 6.334499858412892,\n",
       " 7.374999835155904,\n",
       " 7.197999839112162,\n",
       " 6.690999850444496,\n",
       " 6.450999855808914,\n",
       " 6.619999852031469,\n",
       " 6.359999857842922,\n",
       " 7.070499841962009,\n",
       " 6.164499862212688,\n",
       " 7.065499842073768,\n",
       " 6.261499860044569,\n",
       " 6.66249985108152,\n",
       " 6.977499844040722,\n",
       " 6.507999854534864,\n",
       " 6.835999847203493,\n",
       " 6.250499860290438,\n",
       " 7.7344998271204535,\n",
       " 7.4594998332671825,\n",
       " 7.843499824684113,\n",
       " 7.991499821376055,\n",
       " 6.833499847259373,\n",
       " 7.522499831859022,\n",
       " 8.497999810054898,\n",
       " 7.282999837212264,\n",
       " 7.734999827109277,\n",
       " 8.288999814726413,\n",
       " 8.308499814290553,\n",
       " 7.354999835602939,\n",
       " 8.18699981700629,\n",
       " 7.886999823711813,\n",
       " 7.870499824080616,\n",
       " 8.303999814391137,\n",
       " 8.250499815586954,\n",
       " 7.3764998351223765,\n",
       " 7.636999829299748,\n",
       " 8.162499817553908,\n",
       " 8.623499807249754,\n",
       " 7.888999823667109,\n",
       " 8.504499809909612,\n",
       " 7.380499835032969,\n",
       " 8.061499819811434,\n",
       " 7.740999826975167,\n",
       " 7.8489998245611785,\n",
       " 8.88099980149418,\n",
       " 7.875499823968857,\n",
       " 8.034499820414931,\n",
       " 8.115999818593263,\n",
       " 8.06599981971085,\n",
       " 8.77799980379641,\n",
       " 8.718999805115164,\n",
       " 8.957999799773097,\n",
       " 8.292999814637005,\n",
       " 8.124499818403274,\n",
       " 7.868999824114144,\n",
       " 8.571499808412046,\n",
       " 8.427499811630696,\n",
       " 7.852499824482948,\n",
       " 8.642999806813895,\n",
       " 8.371999812871218,\n",
       " 8.54799980893731,\n",
       " 8.219999816268682,\n",
       " 8.890999801270663,\n",
       " 8.64849980669096,\n",
       " 9.042499797884375,\n",
       " 8.762499804142863,\n",
       " 7.70149982785806,\n",
       " 8.321499813999981,\n",
       " 9.152499795425683,\n",
       " 8.091999819129706,\n",
       " 8.782499803695828,\n",
       " 8.261499815341086,\n",
       " 9.356999790854752,\n",
       " 7.695499827992171,\n",
       " 9.588999785669149,\n",
       " 9.619999784976244,\n",
       " 8.978499799314886,\n",
       " 8.905499800946563,\n",
       " 8.718999805115164,\n",
       " 7.892499823588878,\n",
       " 9.115999796241521,\n",
       " 8.926499800477178,\n",
       " 8.992999798990786,\n",
       " 9.356499790865929,\n",
       " 9.427499789278954,\n",
       " 9.94399977773428,\n",
       " 9.15099979545921,\n",
       " 9.087499796878546,\n",
       " 9.78299978133291,\n",
       " 8.940999800153076,\n",
       " 10.046499775443227,\n",
       " 9.36399979069829,\n",
       " 9.548499786574393,\n",
       " 10.000499776471406,\n",
       " 9.767499781679362,\n",
       " 8.737499804701656,\n",
       " 9.497999787703156,\n",
       " 9.617499785032123,\n",
       " 9.43899978902191,\n",
       " 9.563999786227942,\n",
       " 9.66899978388101,\n",
       " 10.215499771665781,\n",
       " 10.320999769307672,\n",
       " 9.63049978474155,\n",
       " 10.243499771039932,\n",
       " 10.628999762423337,\n",
       " 9.7744997815229,\n",
       " 10.516999764926732,\n",
       " 10.288499770034104,\n",
       " 10.27949977023527,\n",
       " 9.88949977895245,\n",
       " 7.989499821420759,\n",
       " 9.541499786730856,\n",
       " 9.939499777834863,\n",
       " 9.86399977952242,\n",
       " 10.708999760635198,\n",
       " 10.411999767273665,\n",
       " 10.382999767921865,\n",
       " 9.754999781958759,\n",
       " 9.092999796755612,\n",
       " 10.215499771665781,\n",
       " 9.233499793615191,\n",
       " 10.615999762713908,\n",
       " 10.027999775856733,\n",
       " 9.96699977722019,\n",
       " 9.472499788273126,\n",
       " 9.711999782919884,\n",
       " 9.084999796934426,\n",
       " 10.020499776024371,\n",
       " 9.589499785657972,\n",
       " 10.703499760758131,\n",
       " 9.579999785870314,\n",
       " 9.783499781321733,\n",
       " 10.845999757573008,\n",
       " 9.940999777801334,\n",
       " 9.776499781478197,\n",
       " 9.890499778930097,\n",
       " 10.378499768022447,\n",
       " 9.784999781288207,\n",
       " 11.497499743010849,\n",
       " 9.903499778639524,\n",
       " 9.134499795828015,\n",
       " 10.708499760646372,\n",
       " 10.67549976138398,\n",
       " 9.799499780964107,\n",
       " 10.344999768771231,\n",
       " 8.828999802656472,\n",
       " 10.661499761696906,\n",
       " 10.380499767977744,\n",
       " 11.420999744720756,\n",
       " 10.332499769050628,\n",
       " 10.071499774884433,\n",
       " 10.710999760590493,\n",
       " 11.889499734248966,\n",
       " 9.987499776761979,\n",
       " 11.325499746855348,\n",
       " 11.186999749951065,\n",
       " 10.303999769687653,\n",
       " 10.293499769922345,\n",
       " 10.862499757204205,\n",
       " 11.047999753057956,\n",
       " 9.69599978327751,\n",
       " 9.844499779958278,\n",
       " 9.706499783042819,\n",
       " 9.98049977691844,\n",
       " 9.384999790228903,\n",
       " 10.700499760825187,\n",
       " 10.470999765954911,\n",
       " 10.58349976344034,\n",
       " 10.725499760266393,\n",
       " 10.66199976168573,\n",
       " 10.447999766469001,\n",
       " 9.77699978146702,\n",
       " 10.556999764032662,\n",
       " 10.396499767620117,\n",
       " 10.612999762780964,\n",
       " 10.953499755170196,\n",
       " 10.408499767351895,\n",
       " 10.117999773845076,\n",
       " 10.927999755740165,\n",
       " 10.929499755706638,\n",
       " 11.790499736461788,\n",
       " 10.655999761819839,\n",
       " 10.774499759171158,\n",
       " 11.125499751325696,\n",
       " 10.642499762121588,\n",
       " 11.764499737042934,\n",
       " 11.851999735087157,\n",
       " 11.359999746084213,\n",
       " 11.451999744027853,\n",
       " 12.511499720346183,\n",
       " 10.941999755427242,\n",
       " 11.985499732103198,\n",
       " 11.285999747738241,\n",
       " 11.748999737389386,\n",
       " 10.739999759942293,\n",
       " 11.663999739289284,\n",
       " 10.45749976625666,\n",
       " 11.303499747347086,\n",
       " 10.623999762535096,\n",
       " 11.29899974744767,\n",
       " 11.736999737657607,\n",
       " 11.445499744173139,\n",
       " 10.467499766033143,\n",
       " 11.946499732974917,\n",
       " 11.285999747738241,\n",
       " 11.427999744564294,\n",
       " 11.480499743390828,\n",
       " 10.997999754175543,\n",
       " 11.003999754041434,\n",
       " 11.130999751202761,\n",
       " 10.9514997552149,\n",
       " 11.123999751359225,\n",
       " 12.286999725364149,\n",
       " 11.620999740250408,\n",
       " 12.315499724727124,\n",
       " 11.363499746005981,\n",
       " 10.953499755170196,\n",
       " 10.359499768447131,\n",
       " 11.186999749951065,\n",
       " 11.70349973840639,\n",
       " 11.509499742742628,\n",
       " 11.252499748487025,\n",
       " 11.374999745748937,\n",
       " 10.177499772515148,\n",
       " 11.076999752409757,\n",
       " 10.90899975616485,\n",
       " 10.894999756477773,\n",
       " 11.346999746374786,\n",
       " 11.185999749973416,\n",
       " 12.17099972795695,\n",
       " 11.913499733712523,\n",
       " 10.768499759305268,\n",
       " 11.100999751873314,\n",
       " 11.60649974057451,\n",
       " 10.769499759282917,\n",
       " 12.960999710299074,\n",
       " 11.096999751962722,\n",
       " 11.530999742262065,\n",
       " 11.173499750252812,\n",
       " 11.602499740663916,\n",
       " 11.871999734640122,\n",
       " 11.169999750331044,\n",
       " 11.515499742608517,\n",
       " 11.431499744486064,\n",
       " 11.421499744709582,\n",
       " 10.582499763462692,\n",
       " 11.10649975175038,\n",
       " 12.137999728694558,\n",
       " 12.084499729890377,\n",
       " 11.960999732650816,\n",
       " 11.610499740485102,\n",
       " 11.959499732684344,\n",
       " 12.163999728113414,\n",
       " 10.545499764289707,\n",
       " 11.549499741848559,\n",
       " 13.138999706320465,\n",
       " 12.231499726604671,\n",
       " 10.78199975900352,\n",
       " 11.377499745693058,\n",
       " 11.793499736394732,\n",
       " 11.726999737881124,\n",
       " 11.687999738752842,\n",
       " 12.10549972942099,\n",
       " 13.032999708689749,\n",
       " 11.788499736506491,\n",
       " 12.093999729678035,\n",
       " 11.121499751415104,\n",
       " 11.495499743055552,\n",
       " 11.891999734193087,\n",
       " 13.019499708991498,\n",
       " 12.639999717473984,\n",
       " 12.49549972070381,\n",
       " 12.811999713629485,\n",
       " 12.22549972673878,\n",
       " 12.524999720044434,\n",
       " 12.63699971754104,\n",
       " 11.709999738261104,\n",
       " 12.426499722246081,\n",
       " 13.004999709315598,\n",
       " 13.090999707393348,\n",
       " 12.41899972241372,\n",
       " 12.962499710265547,\n",
       " 13.899999689310789,\n",
       " 13.751999692618847,\n",
       " 11.94449973301962,\n",
       " 13.263999703526498,\n",
       " 12.689499716367573,\n",
       " 11.742999737523496,\n",
       " 12.154999728314579,\n",
       " 12.038999730907381,\n",
       " 11.370999745838343,\n",
       " 12.90949971145019,\n",
       " 12.264499725867063,\n",
       " 13.863999690115453,\n",
       " 11.810499736014753,\n",
       " 13.593499696161597,\n",
       " 13.40249970043078,\n",
       " 13.715999693423509,\n",
       " 12.65299971718341,\n",
       " 13.383499700855463,\n",
       " 12.269499725755304,\n",
       " 12.5449997195974,\n",
       " 12.873999712243677,\n",
       " 14.172999683208763,\n",
       " 12.880999712087213,\n",
       " 13.681499694194645,\n",
       " 11.84999973513186,\n",
       " 13.480499698687344,\n",
       " 13.526499697659165,\n",
       " 13.227499704342335,\n",
       " 13.472499698866159,\n",
       " 13.53799969740212,\n",
       " 12.85749971261248,\n",
       " 13.766499692294747,\n",
       " 13.023999708890916,\n",
       " 12.089999729767442,\n",
       " 13.626999695412815,\n",
       " 13.496999698318541,\n",
       " 13.688999694027007,\n",
       " 13.789499691780657,\n",
       " 13.922499688807875,\n",
       " 13.122999706678092,\n",
       " 14.069999685510993,\n",
       " 13.206999704800547,\n",
       " 13.804999691434205,\n",
       " 13.436499699670822,\n",
       " 14.561499674525113,\n",
       " 13.8504996904172,\n",
       " 12.75099971499294,\n",
       " 13.471999698877335,\n",
       " 13.08749970747158,\n",
       " 13.406999700330198,\n",
       " 13.524999697692692,\n",
       " 14.207999682426452,\n",
       " 13.7364996929653,\n",
       " 13.581999696418643,\n",
       " 13.975499687623232,\n",
       " 13.54649969721213,\n",
       " 13.771499692182989,\n",
       " 14.009999686852098,\n",
       " 13.516499697882683,\n",
       " 12.213499727007001,\n",
       " 14.986499665025622,\n",
       " 12.642999717406928,\n",
       " 14.083499685209244,\n",
       " 14.26949968105182,\n",
       " 13.354499701503665,\n",
       " 13.970499687734991,\n",
       " 13.410499700251966,\n",
       " 14.22349968208,\n",
       " 14.746999670378864,\n",
       " 14.347999679297208,\n",
       " 15.455999654531478,\n",
       " 14.669499672111124,\n",
       " 14.88699966724962,\n",
       " 14.124499684292823,\n",
       " 15.746999648027122,\n",
       " 14.641499672736973,\n",
       " 14.894999667070806,\n",
       " 15.507499653380364,\n",
       " 16.327499635051936,\n",
       " 14.292999680526554,\n",
       " 14.01149968681857,\n",
       " 15.74549964806065,\n",
       " 13.884499689657241,\n",
       " 14.422499677632004,\n",
       " 14.724499670881778,\n",
       " 15.059999663382769,\n",
       " 15.457499654497951,\n",
       " 14.954999665729702,\n",
       " 14.345999679341912,\n",
       " 14.54799967482686,\n",
       " 14.675499671977013,\n",
       " 15.878499645087867,\n",
       " 14.88099966738373,\n",
       " 14.624999673105776,\n",
       " 15.801499646808953,\n",
       " 15.667499649804085,\n",
       " 14.675999671965837,\n",
       " 15.416499655414373,\n",
       " 15.907999644428491,\n",
       " 15.298499658051878,\n",
       " 15.788499647099524,\n",
       " 16.036999641545115,\n",
       " 14.640999672748148,\n",
       " 14.935999666154384,\n",
       " 15.44049965487793,\n",
       " 15.037999663874507,\n",
       " 14.96449966551736,\n",
       " 15.01549966437742,\n",
       " 16.33749963482842,\n",
       " 14.780999669618904,\n",
       " 15.334499657247216,\n",
       " 14.709499671217054,\n",
       " 15.216999659873546,\n",
       " 15.020499664265662,\n",
       " 15.016999664343894,\n",
       " 15.803499646764248,\n",
       " 14.238499681744724,\n",
       " 16.409999633207917,\n",
       " 15.63399965055287,\n",
       " 14.520999675430357,\n",
       " 15.695499649178236,\n",
       " 15.19449966037646,\n",
       " 15.742499648127705,\n",
       " 16.719999626278877,\n",
       " 16.376999633945523,\n",
       " 15.756499647814781,\n",
       " 15.419999655336142,\n",
       " 14.70299967136234,\n",
       " 14.764499669987709,\n",
       " 14.088499685097485,\n",
       " 14.882499667350203,\n",
       " 14.90749966679141,\n",
       " 13.871499689947814,\n",
       " 14.49949967591092,\n",
       " 14.067999685555696,\n",
       " 15.119999662041664,\n",
       " 14.425999677553772,\n",
       " 14.489499676134438,\n",
       " 15.218999659828842,\n",
       " 13.527999697625637,\n",
       " 14.494999676011503,\n",
       " 14.80599966906011,\n",
       " 15.131999661773444,\n",
       " 13.530499697569757,\n",
       " 13.661999694630504,\n",
       " 13.521499697770924,\n",
       " 14.652999672479927,\n",
       " 15.496999653615058,\n",
       " 14.58549967398867,\n",
       " 14.802999669127166,\n",
       " 14.225499682035297,\n",
       " 14.410499677900225,\n",
       " 15.297999658063054,\n",
       " 14.44249967718497,\n",
       " 14.472499676514417,\n",
       " 15.545999652519821,\n",
       " 14.801999669149518,\n",
       " 15.085499662812799,\n",
       " 14.722999670915305,\n",
       " 14.26349968118593,\n",
       " 14.184999682940543,\n",
       " 14.572999674268067,\n",
       " 13.823499691020697,\n",
       " 13.834999690763652,\n",
       " 15.152499661315233,\n",
       " 15.890499644819647,\n",
       " 14.975999665260314,\n",
       " 13.518499697837978,\n",
       " 15.239999659359455,\n",
       " 14.785499669518321,\n",
       " 15.901999644562602,\n",
       " 14.421499677654356,\n",
       " 15.244499659258873,\n",
       " 15.61849965089932,\n",
       " 15.674499649647624,\n",
       " 14.486999676190317,\n",
       " 15.335999657213687,\n",
       " 15.143499661516397,\n",
       " 14.322999679856002,\n",
       " 14.7684996698983,\n",
       " 15.85699964556843,\n",
       " 15.726999648474157,\n",
       " 15.017499664332718,\n",
       " 15.289499658253044,\n",
       " 14.555999674648046,\n",
       " 16.05799964107573,\n",
       " 16.024999641813338,\n",
       " 15.759499647747726,\n",
       " 15.640499650407582,\n",
       " 14.594999673776329,\n",
       " 14.807999669015407,\n",
       " 14.800499669183045,\n",
       " 15.369499656464905,\n",
       " 14.992499664891511,\n",
       " 15.251999659091235,\n",
       " 14.928999666310848,\n",
       " 14.974499665293843,\n",
       " 15.560499652195722,\n",
       " 15.77949964730069,\n",
       " 16.627499628346413,\n",
       " 15.445999654754996,\n",
       " 17.05799961872399,\n",
       " 16.308999635465444,\n",
       " 15.057499663438648,\n",
       " 16.75649962546304,\n",
       " 16.017499641980976,\n",
       " 15.661499649938197,\n",
       " 16.185499638225885,\n",
       " 15.709499648865313,\n",
       " 16.52199963070452,\n",
       " 17.367499611806124,\n",
       " 16.53499963041395,\n",
       " 17.224499615002422,\n",
       " 16.26149963652715,\n",
       " 16.53749963035807,\n",
       " 16.63699962813407,\n",
       " 16.923999621719123,\n",
       " 16.265999636426567,\n",
       " 15.964499643165619,\n",
       " 15.921999644115568,\n",
       " 17.50749960867688,\n",
       " 16.229499637242405,\n",
       " 16.012499642092735,\n",
       " 17.219999615103006,\n",
       " 17.497499608900398,\n",
       " 17.178499616030603,\n",
       " 15.846999645791948,\n",
       " 16.832999623753132,\n",
       " 16.69749962678179,\n",
       " 16.859499623160808,\n",
       " 17.397999611124398,\n",
       " 16.32299963515252,\n",
       " 17.833999601379038,\n",
       " 16.937499621417373,\n",
       " 17.634999605827034,\n",
       " 16.54349963022396,\n",
       " 16.99499962013215,\n",
       " 17.150999616645276,\n",
       " 17.5824996070005,\n",
       " 17.72399960383773,\n",
       " 15.913999644294382,\n",
       " 18.618499583844095,\n",
       " 17.610499606374653,\n",
       " 17.0229996195063,\n",
       " 16.920999621786176,\n",
       " 16.334499634895472,\n",
       " 17.67099960502237,\n",
       " 18.06549959620461,\n",
       " 16.947499621193856,\n",
       " 18.645999583229422,\n",
       " 17.078999618254603,\n",
       " 17.890999600104987,\n",
       " 18.220999592728912,\n",
       " 16.52649963060394,\n",
       " 17.4249996105209,\n",
       " 16.713499626424163,\n",
       " 17.592499606776983,\n",
       " 16.891999622434376,\n",
       " 18.29449959108606,\n",
       " 17.10899961758405,\n",
       " 17.44099961016327,\n",
       " 18.366999589465557,\n",
       " 18.813499579485505,\n",
       " 16.72499962616712,\n",
       " 17.37699961159378,\n",
       " 18.5439995855093,\n",
       " 17.56699960734695,\n",
       " 16.9359996214509,\n",
       " 17.389499611314385,\n",
       " 17.842999601177873,\n",
       " 18.099999595433474,\n",
       " 18.567499584984034,\n",
       " 17.542999607883395,\n",
       " 17.684999604709446,\n",
       " 16.749999625608325,\n",
       " 17.24599961452186,\n",
       " 17.621499606128783,\n",
       " 18.178999593667687,\n",
       " 17.98699959795922,\n",
       " 16.682999627105893,\n",
       " 17.4519996099174,\n",
       " 16.587499629240483,\n",
       " 17.815999601781368,\n",
       " 18.46749958721921,\n",
       " 16.31099963542074,\n",
       " 18.482999586872758,\n",
       " 17.18449961589649,\n",
       " 17.45049960995093,\n",
       " 17.52099960837513,\n",
       " 18.85649957852438,\n",
       " 18.22049959274009,\n",
       " 17.749999603256583,\n",
       " 16.633499628212302,\n",
       " 17.976999598182736,\n",
       " 17.180999615974724,\n",
       " 17.01099961977452,\n",
       " 17.685499604698272,\n",
       " 17.20349961547181,\n",
       " 17.582999606989326,\n",
       " 17.51349960854277,\n",
       " 15.587499651592225,\n",
       " 16.295499635767193,\n",
       " 16.264499636460094,\n",
       " 17.17199961617589,\n",
       " 15.915999644249677,\n",
       " 15.766499647591264,\n",
       " 15.366999656520784,\n",
       " 15.291499658208341,\n",
       " 15.7879996471107,\n",
       " 16.43799963258207,\n",
       " 14.721499670948834,\n",
       " 14.982499665115029,\n",
       " 13.976999687589705,\n",
       " 15.623499650787561,\n",
       " 15.244499659258873,\n",
       " 15.565499652083963,\n",
       " 14.613999673351646,\n",
       " 14.651499672513456,\n",
       " 14.557499674614519,\n",
       " 14.900999666936695,\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from a2c import A2C_PPO_LOSS\n",
    "from itertools import chain\n",
    "import torch.optim as optim\n",
    "learning_rate = 1e-3\n",
    "episode = 10000\n",
    "tmax = 1000\n",
    "state_dim = 33\n",
    "action_dim = 4\n",
    "\n",
    "# Initializing policy network, optimizer and agent\n",
    "policy_value_network = Policy_Value_Network(state_dim,action_dim).to(device)\n",
    "optimizer = optim.Adam(policy_value_network.parameters(), lr=learning_rate)\n",
    "a2c_agent = A2C_PPO_LOSS(policy_value_network,\n",
    "                 optimizer,\n",
    "                 value_loss_coef=1,\n",
    "                 n_boot_strap=1,\n",
    "                 normalize_advantage =True,\n",
    "                 use_gae_advantage = True,\n",
    "                 lambda_bootstrap_schedule = lambda old_value, rewards: min([0.9999*old_value,0.3]),\n",
    "                 lambda_bootstrap_start=0.8,\n",
    "                 ppo_value_epsilon_schedule = lambda old_value, rewards: min([0.9996*old_value, 0.1]),\n",
    "                 ppo_value_epsilon_start = 0.5,\n",
    "                 SGD_steps=4,\n",
    "                 ppo_policy_epsilon_schedule=lambda old_value, rewards: min([0.9996*old_value, 0.03]),\n",
    "                 ppo_policy_epsilon_start=0.15,\n",
    "                 entropy_reg_schedule = lambda old_value, rewards: 0.9999*old_value,\n",
    "                 entropy_reg_start=0.01,\n",
    "                 gamma_schedule = lambda old_value, rewards: 1.- 0.9999*(1. - old_value),\n",
    "                 gamma_start = 0.985,\n",
    "                 target_score=30,\n",
    "                 target_score_window=100,\n",
    "                 action_transform = lambda x: -1+2*x,\n",
    "                 verbosity = 100)\n",
    "a2c_agent.training(env, tmax, tmax, episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae6306-ad7e-49a6-9942-a9dcee572f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import beta\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class Policy_Value_Network(nn.Module):\n",
    "    def __init__(self, input_size, action_size):\n",
    "        super(Policy_Value_Network, self).__init__()\n",
    "        # outputs beta likelyhood parameters\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fcalpha = nn.Linear(64, action_size)\n",
    "        self.fcbeta = nn.Linear(64, action_size)\n",
    "        self.fcval = nn.Linear(64, 1)\n",
    "        self.softplus_act = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        a = self.softplus_act(self.fcalpha(x)) + 1.\n",
    "        b = self.softplus_act(self.fcbeta(x)) + 1.\n",
    "        beta_dist = beta.Beta(a,b)\n",
    "        value = self.fcval(x)\n",
    "        return beta_dist, value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d2438-a7bb-4f77-b91a-2e50d124f2d4",
   "metadata": {},
   "source": [
    "### Defining function to collect trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39056301-224c-4a5b-99b6-0dc0bdbf9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trajectories(policy_value, env, tmax):\n",
    "    states_list = []\n",
    "    actions_list = []\n",
    "    rewards_list = []\n",
    "    log_probs_list = []\n",
    "    values_list = []\n",
    "    \n",
    "    states = env.reset_env()                             # reset the environment    \n",
    "    scores = np.zeros(env.nagents) \n",
    "    t = 0\n",
    "    while t <= tmax:\n",
    "        states_tensor = torch.tensor(states, dtype=torch.float32, device=device) \n",
    "        states_list.append(states_tensor)                         # storing states\n",
    "        dists, values = policy_value(states_tensor)        # getting distribution out of the policy network\n",
    "        \n",
    "        # getting log prob of sampled actions\n",
    "        samples = dists.sample()                            # sampling from distribution\n",
    "        log_probs = torch.sum(dists.log_prob(samples),1)\n",
    "        log_probs_list.append(log_probs) # storing model probs\n",
    "        \n",
    "        # converting samples in [0,1] to actions in [-1,1]\n",
    "        actions_list.append(samples) \n",
    "        actions = -1. + 2. * samples.detach().cpu().numpy()\n",
    "        \n",
    "        # generating rewards by interacting with environment\n",
    "        next_states, rewards, dones = env.take_action(actions)\n",
    "        rewards_tensor = torch.tensor(rewards, dtype=torch.float32, device=device)[None,:]\n",
    "        rewards_list.append(rewards_tensor)                # storing rewards\n",
    "        \n",
    "        # storing values for each state\n",
    "        values_list.append(torch.transpose(values,0,1))\n",
    "        scores += np.array(rewards)                        # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "        t += 1\n",
    "        \n",
    "    next_states_tensor = torch.tensor(next_states, dtype=torch.float32, device=device) \n",
    "    states_list.append(next_states_tensor)                        # storing states\n",
    "    dists, values = policy_value(next_states_tensor)\n",
    "    dones_tensor = torch.tensor(dones, dtype=torch.float32, device=device)[None,:]\n",
    "    values = torch.transpose(values,0,1)\n",
    "    \n",
    "    values = torch.where(dones_tensor == 0,values, torch.zeros_like(values))\n",
    "    values_list.append(values)\n",
    "    rewards_list.append(values)\n",
    "    \n",
    "    return torch.cat(states_list,0), torch.cat(actions_list,0), \\\n",
    "            torch.cat(rewards_list,0), torch.cat(values_list,0), torch.cat(log_probs_list,0), scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525ea26-b533-451c-a1b2-d626ce4c3892",
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions,rewards, log_prob, values, scores = collect_trajectories(policy_value_network, env, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad7e8a-8f5a-4d15-b689-bf11f34dee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "states.shape, actions.shape, rewards.shape, log_prob.shape, values.shape, scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208b50f-d1b5-4df6-968e-6f455247d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_future_rewards(R, gamma):\n",
    "    discounts = np.array([gamma**i for i in range(R.shape[0])])\n",
    "    dis_R = R*discounts[:,None]\n",
    "    tot_dis_f_R = dis_R[::-1].cumsum(axis=0)[::-1]\n",
    "    tot_dis_f_R = tot_dis_f_R/discounts[:,None]\n",
    "    return tot_dis_f_R\n",
    "    \n",
    "def kstep_boot_strapped_advantage(Rf, n_bootstrap, V, gamma):\n",
    "    A = Rf[:-n_bootstrap] + (gamma**n_bootstrap) * (V[n_bootstrap:] - Rf[n_bootstrap:])  \\\n",
    "        - V[:-n_bootstrap]\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27214b-08b3-4b99-a657-398a32d71afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = rewards\n",
    "gamma = 0.99\n",
    "discounts = torch.tensor([[gamma**i] for i in range(R.shape[0])], dtype=torch.float64, device=device)\n",
    "dis_R = R*discounts\n",
    "tot_dis_f_R = dis_R + dis_R.sum(dim=0, keepdims=True) - dis_R.cumsum(dim=0)\n",
    "tot_dis_f_R = tot_dis_f_R/discounts\n",
    "A = tot_dis_f_R.detach().numpy()\n",
    "\n",
    "B = total_future_rewards(R.detach().numpy(), gamma)\n",
    "(A-B).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf2bffc-de59-460f-ab45-f0f7044d9a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "states[0].shape, actions[0].shape, rewards[0].shape, log_prob[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e5d32-f031-43e6-ade0-f1570f714d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(dones, dtype=torch.float32, device=device)[None,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19293d49-10b5-4535-b26c-6141ebe4629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed96a0-581e-4016-9c63-73041bb5208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "# training loop max iterations\n",
    "episode = 1500\n",
    "discount_rate = .99\n",
    "epsilon = 0.1\n",
    "beta_val = .01\n",
    "tmax = 1000\n",
    "SGD_epoch = 4\n",
    "learning_rate = 1e-4\n",
    "score_window_len = 100\n",
    "state_dim = 33\n",
    "action_dim = 4\n",
    "max_score = 30\n",
    "n_bootstrap = 5\n",
    "\n",
    "# Initializing policy and value network, and optimizer\n",
    "policy_value_network = Policy_Value(state_dim,action_dim).to(device)\n",
    "\n",
    "states, actions, rewards, log_probs, values,  scores = \\\n",
    "            collect_trajectories(policy_value_network, env, tmax)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec9703-c7a9-40ba-88f7-48da145acb94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfef9af-1c5e-4f00-a796-89c649801fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rewards.shape, values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa1db6-58e6-4b66-85f2-771d33c00af1",
   "metadata": {},
   "source": [
    "### Defining k step booststrap reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e273d3-0018-488c-b519-af62bbb36292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_future_rewards(R, gamma):\n",
    "    discounts = np.array([gamma**i for i in range(R.shape[0])])\n",
    "    dis_R = R*discounts[:,None]\n",
    "    tot_dis_f_R = dis_R[::-1].cumsum(axis=0)[::-1]\n",
    "    tot_dis_f_R = tot_dis_f_R/discounts[:,None]\n",
    "    return tot_dis_f_R\n",
    "    \n",
    "def kstep_boot_strapped_advantage(Rf, n_bootstrap, V, gamma):\n",
    "    A = Rf[:-n_bootstrap] + (gamma**n_bootstrap) * (V[n_bootstrap:] - Rf[n_bootstrap:])  \\\n",
    "        - V[:-n_bootstrap]\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b3f29f-55ac-41e4-99f2-a69b0d80fc57",
   "metadata": {},
   "source": [
    "### Defining Advantage Actor-Critic update function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c6182e-29b1-47f1-972e-d98c2f629716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def update_A2C(optimizer, \n",
    "               policy_value_network, \n",
    "               old_log_probs, \n",
    "               states, \n",
    "               actions, \n",
    "               rewards,\n",
    "               values,\n",
    "               gamma = 0.995, \n",
    "               epsilon=0.1, \n",
    "               beta_val=0.01, \n",
    "               n_bootstrap=5):\n",
    "    \n",
    "    start = datetime.now()\n",
    "    # old probs\n",
    "    old_log_probs = torch.tensor(old_log_probs[:-n_bootstrap+1].flatten(), \n",
    "                             dtype=torch.float32, device=device)\n",
    "        \n",
    "    # total future reward for value function update\n",
    "    Rf = total_future_rewards(rewards, gamma)\n",
    "    RF = torch.tensor(Rf[:-n_bootstrap].flatten(),dtype=torch.float32, device=device)\n",
    "    \n",
    "    # advantage calculation for policy update\n",
    "    A = kstep_boot_strapped_advantage(Rf,n_bootstrap,values,gamma)\n",
    "    A = torch.tensor(A.flatten(), dtype=torch.float32, device=device)\n",
    "    \n",
    "    # actions\n",
    "    actions = (np.concatenate(actions[:-n_bootstrap+1]) + 1.)/2.\n",
    "    actions = torch.tensor(actions, dtype=torch.float32, device=device)\n",
    "    \n",
    "    # convert states to prob and logprob\n",
    "    states = torch.cat(states[:-n_bootstrap],0)\n",
    "    dist,pred_values = policy_value_network(states)\n",
    "    \n",
    "    # PPO loss on policy\n",
    "    new_log_probs = torch.sum(dist.log_prob(actions),1)\n",
    "    log_ratio = new_log_probs - old_log_probs\n",
    "    ratio = torch.exp(log_ratio)\n",
    "    clipped_ratio = torch.clamp(ratio, 1.-epsilon, 1.+epsilon)\n",
    "    surr_clipped_erew = A*torch.min(ratio, clipped_ratio)\n",
    "    entropy = torch.sum(dist.entropy(),1)\n",
    "    policy_loss = -torch.mean(surr_clipped_erew + beta_val*entropy)\n",
    "    \n",
    "    # Value function loss\n",
    "    value_loss = torch.mean(torch.pow(RF - pred_values[:,0],2))\n",
    "    \n",
    "    # total loss\n",
    "    total_loss = policy_loss + value_loss\n",
    "    \n",
    "    \n",
    "    # updating policy network\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    del total_loss\n",
    "    \n",
    "    return policy_value_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec695469-087d-4e99-b656-130b12262ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "# training loop max iterations\n",
    "episode = 1500\n",
    "discount_rate = .99\n",
    "epsilon = 0.1\n",
    "beta_val = .01\n",
    "tmax = 1000\n",
    "SGD_epoch = 4\n",
    "learning_rate = 1e-4\n",
    "score_window_len = 100\n",
    "state_dim = 33\n",
    "action_dim = 4\n",
    "max_score = 30\n",
    "n_bootstrap = 5\n",
    "\n",
    "# Initializing policy and value network, and optimizer\n",
    "policy_value_network = Policy_Value(state_dim,action_dim).to(device)\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(policy_value_network.parameters(), lr=learning_rate)\n",
    "\n",
    "# keep track of progress\n",
    "mean_rewards = []\n",
    "mean_rewards_window = deque(maxlen=score_window_len)\n",
    "for e in range(episode):\n",
    "\n",
    "    # collect trajectories\n",
    "    policy_value_network.eval()\n",
    "    with torch.no_grad():\n",
    "        states, actions, rewards, log_probs, values,  scores = \\\n",
    "            collect_trajectories(policy_value_network, env, tmax)\n",
    "        \n",
    "    # gradient ascent step\n",
    "    policy_value_network.train()\n",
    "    with torch.enable_grad()\n",
    "    for _ in range(SGD_epoch):\n",
    "        policy_value_network = update_A2C(optimizer, \n",
    "               policy_value_network, \n",
    "               log_probs, \n",
    "               states, \n",
    "               actions, \n",
    "               rewards,\n",
    "               values,\n",
    "               gamma = discount_rate, \n",
    "               epsilon=epsilon, \n",
    "               beta_val=beta_val, \n",
    "               n_bootstrap=n_bootstrap)\n",
    "        \n",
    "    # the clipping parameter reduces as time goes on\n",
    "    epsilon*=.995\n",
    "    \n",
    "    # the regulation term also reduces\n",
    "    # this reduces exploration in later runs\n",
    "    beta_val*=.995\n",
    "    \n",
    "    # get the average reward of the parallel environments\n",
    "    mean_of_all_agents = np.mean(scores)\n",
    "    mean_rewards.append(mean_of_all_agents)\n",
    "    mean_rewards_window.append(mean_of_all_agents)\n",
    "    avg_of_last_x_episodes = np.mean(mean_rewards_window)\n",
    "    \n",
    "    # display some progress every 20 iterations\n",
    "    print(f\"\\r Episode : {e+1}\\t Average reward in last 100 episode : {avg_of_last_x_episodes:.2f}\",end=\"\")\n",
    "    if (e+1)%50 ==0 :\n",
    "        print(f\"\\r Episode : {e+1}\\t Average reward in last 100 episode : {avg_of_last_x_episodes:.2f}\")\n",
    "    \n",
    "    if avg_of_last_x_episodes >= max_score:\n",
    "        print(f\"Environment solved in episodes = {e+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27cbe2-6098-42f5-908f-e0d7716bc73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b2b0a-0383-4d0b-9775-4fa4724d147b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc12bfc8-e8ab-450f-afe2-501c3aaf88ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity_assignment",
   "language": "python",
   "name": "udacity_assignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
